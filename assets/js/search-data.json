{
  
    
        "post0": {
            "title": "Setting machine type in a Vertex AI Pipelines component",
            "content": "Summary . Even if both are using the same service, setting machine type, CPU and RAM in a Vertex AI Custom Training job using the Python SDK is different from setting machine type, CPU and RAM in tasks in Vertex AI Pipelines. . Setting machine type in a Vertex AI Custom Training job . To set machine type, CPU and RAM in a Vertex AI Custom Training job, you must use the google.cloud.aiplatform SDK. You can configure any type of machine according to this table. . To set the machine type, you must use worker_pool_specs and pass as argument to the method google.cloud.aiplatform.CustomJob: . worker_pool_specs = [ { &quot;machine_spec&quot;: { &quot;machine_type&quot;: &quot;n1-standard-4&quot;, &quot;accelerator_type&quot;: &quot;NVIDIA_TESLA_K80&quot;, &quot;accelerator_count&quot;: 1, }, &quot;replica_count&quot;: 1, &quot;container_spec&quot;: { &quot;image_uri&quot;: container_image_uri, &quot;command&quot;: [], &quot;args&quot;: [], }, } ] my_job = aiplatform.CustomJob( display_name=&#39;my_job&#39;, worker_pool_specs=worker_pool_specs, labels={&#39;my_key&#39;: &#39;my_value&#39;}, ) my_job.run() . Setting machine type in Vertex AI Pipelines . To set machine CPU and RAM in a step in Vertex AI Training job, you must use the kfp.v2.dsl SDK, and the methods set_memory_limit and set_cpu_limit. Vertex AI Pipelines will automatically find the best matching machine type to run the component, typically a e2-standard machine type. . from kfp.v2 import dsl @dsl.pipeline(name=&#39;custom-container-pipeline&#39;) def pipeline(): generate = generate_op() train = (train_op( training_data=generate.outputs[&#39;training_data&#39;], test_data=generate.outputs[&#39;test_data&#39;], config_file=generate.outputs[&#39;config_file&#39;]). set_cpu_limit(&#39;CPU_LIMIT&#39;). set_memory_limit(&#39;MEMORY_LIMIT&#39;). add_node_selector_constraint(SELECTOR_CONSTRAINT). set_gpu_limit(GPU_LIMIT)) . However, you cannot choose a specific machine type using set_memory_limit and set_cpu_limit. Workaround is to use the create_custom_training_job_from_component method from google_cloud_pipeline_components to translate a Python component into a Vertex AI Custom Job, which allows you to specify particular Google Cloud specific machine resources, including machine types, accelerator types, among many other options. . Example: . import kfp from kfp.v2 import dsl from kfp.v2.dsl import component from google_cloud_pipeline_components.v1.custom_job import create_custom_training_job_from_component # Create a normal Python component @component(output_component_file=&quot;my_python_component.yaml&quot;, base_image=&quot;python:3.9&quot;) def my_python_component(): import time time.sleep(1) # Convert the above component into a Custom Training job custom_training_job = create_custom_training_job_from_component( my_python_component, display_name = &#39;test-component&#39;, machine_type = &#39;n1-standard-8&#39;, accelerator_type=&#39;NVIDIA_TESLA_P4&#39;, accelerator_count=&#39;1&#39; ) # Define a pipeline that runs the above Custom Training job @dsl.pipeline( name=&quot;resource-spec-request&quot;, description=&quot;A simple pipeline that requests GCP machine resource&quot;, pipeline_root=PIPELINE_ROOT, ) def pipeline(): training_job_task = custom_training_job( project=PROJECT_ID, location=REGION, ).set_display_name(&#39;training-job-task&#39;) .",
            "url": "https://rafaelsf80.github.io/blog/vertex%20ai/2022/08/21/pipelines-set-cpu-ram.html",
            "relUrl": "/vertex%20ai/2022/08/21/pipelines-set-cpu-ram.html",
            "date": " • Aug 21, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Adding InstanceID on Vertex AI Batch Prediction",
            "content": "Summary . In Vertex AI Batch Prediction there is no way to pass Instance ID (or key ID) along with the inputs when using XGBoost or Sickit-learn prebuilt containers. Due to the parallelization done in Vertex AI, the order of inputs can not be maintained, so even if the inputs are printed with outputs, because they are out of order, it may be complicated for large datasets to know what prediction results map to which instances. . A feature request is open and can be tracked here. . This tutorial shows a Custom Container for predictions that solves this issue for a Scikit learn model. Using inputs with Instance IDs (on first column), they are removed before calling the prediction. . Example: . For this input (instance ID on first column): . [1,-0.37078722949973075,-0.09383565010748596,-0.11347464767250347,0.12246106838945217,0.10186437443386016,0.1905715671716009] . The following output is printed in Vertex AI Batch prediction (note instance ID is converted to float): . {&quot;instance&quot;: [1.0,-0.37078722949973075,-0.09383565010748596,-0.11347464767250347,0.12246106838945217,0.10186437443386016,0.1905715671716009] ], &quot;prediction&quot;: 46} . Custom Container image . A Custom Container image for predictions is required. Custom Container image requires that the container must run an HTTP server. Specifically, the container must listen and respond to liveness checks, health checks, and prediction requests. . This tutorial uses FastAPI and Uvicorn to implement the HTTP server. The HTTP server must listen for requests on 0.0.0.0. Uvicorn is an ASGI web server implementation for Python. Uvicorn currently supports HTTP/1.1 and WebSockets. Here is a docker image with Uvicorn managed by Gunicorn for high-performance FastAPI web applications in Python 3.6+ with performance auto-tuning. An uvicorn server is launched with: . uvicorn main:app --host 0.0.0.0 --port 7080 . Set up . Train the model with python3 train/train.py. The training dataset is located at train/input_data.csv | Move the resulting ..pkl model to the custom/model directory. The custom directory contains the Dockerfile to generate the Custom Container image. Follow ths instructions below under section Upload and Online deployment in Vertex AI prediction. It will upload the model to Vertex AI and, although not required for batch, will create an online endpoint. | Make a Batch prediction following instructions under section below Batch prediction on Vertex AI. | Running docker locally . Build and run locally (for info see here) . docker build -t demo_basic_model . docker run -p 7080:7080 -e AIP_HTTP_PORT=7080 -e AIP_HEALTH_ROUTE=/health -e AIP_PREDICT_ROUTE=/predict demo_basic_model:latest [...] INFO: Started server process [1] INFO: Waiting for application startup. INFO: Application startup complete. INFO: Uvicorn running on http://0.0.0.0:7080 (Press CTRL+C to quit) . To access container shell: . docker run -it --rm -p 7080:7080 --name=demo_basic_model -e AIP_HTTP_PORT=7080 -e AIP_HEALTH_ROUTE=/health -e AIP_PREDICT_ROUTE=/predict -e AIP_STORAGE_URI=&#39;gs://argolis-vertex-europewest4&#39; 0395efe5870d /bin/bash . Prediction example: . curl -i -X POST http://localhost:7080/predict -d &quot;{ &quot;instances &quot;: [[1,-0.37078722949973075,-0.09383565010748596,-0.11347464767250347,0.12246106838945217,0.10186437443386016,0.1905715671716009],[2,-0.37078722949973075,-0.09383565010748596,-0.11347464767250347,0.12246106838945217,0.10186437443386016,0.1905715671716009]]}&quot; HTTP/1.1 200 OK date: Sun, 03 Jul 2022 14:54:39 GMT server: uvicorn content-length: 21 content-type: application/json {&quot;predictions&quot;:[5,5]} . Prediction example with local file instance_test.json: . curl -i -X POST -d @custom/instances_test.json -H &quot;Content-Type: application/json; charset=uost:7080/predict HTTP/1.1 200 OK date: Sun, 03 Jul 2022 14:56:39 GMT server: uvicorn content-length: 21 content-type: application/json {&quot;predictions&quot;:[8,8]} . Upload and Online deployment in Vertex AI prediction . Push docker image to Artifact Registry: . gcloud auth configure-docker europe-west4-docker.pkg.dev gcloud builds submit --tag europe-west4-docker.pkg.dev/argolis-rafaelsanchez-ml-dev/ml-pipelines-repo/demo_basic_model . Upload model to Vertex AI prediction: . from google.cloud import aiplatform STAGING_BUCKET = &#39;gs://argolis-vertex-europewest4&#39; PROJECT_ID = &#39;argolis-rafaelsanchez-ml-dev&#39; LOCATION = &#39;europe-west4&#39; aiplatform.init(project=PROJECT_ID, staging_bucket=STAGING_BUCKET, location=LOCATION) DEPLOY_IMAGE = &#39;europe-west4-docker.pkg.dev/argolis-rafaelsanchez-ml-dev/ml-pipelines-repo/demo_basic_model&#39; HEALTH_ROUTE = &quot;/health&quot; PREDICT_ROUTE = &quot;/predict&quot; SERVING_CONTAINER_PORTS = [7080] model = aiplatform.Model.upload( display_name=f&#39;custom-model-uvicorn&#39;, description=f&#39;Scikit-learn mdoel with Uviron and FastAPI&#39;, serving_container_image_uri=DEPLOY_IMAGE, serving_container_predict_route=PREDICT_ROUTE, serving_container_health_route=HEALTH_ROUTE, serving_container_ports=SERVING_CONTAINER_PORTS, ) print(model.resource_name) # Retrieve a Model on Vertex model = aiplatform.Model(model.resource_name) print(model.resource_name) # Deploy model endpoint = model.deploy( machine_type=&#39;n1-standard-2&#39;, sync=False ) endpoint.wait() # Retrieve an Endpoint on Vertex endpoint = aiplatform.Endpoint(&#39;projects/989788194604/locations/europe-west4/endpoints/4614905388473516032&#39;) print(endpoint.predict([[1, 0.16877874957321273,0.20526086240043687,0.011701852935588793,1.3426588560447468,0.28517943828011344,-0.48931828100278363], [2, 0.16877874957321273,0.20526086240043687,0.011701852935588793,1.3426588560447468,0.28517943828011344,-0.48931828100278363]])) # Output: [8 8] . Predict using REST API online endpoint: . curl -X POST -H &quot;Authorization: Bearer $(gcloud auth print-access-token)&quot; -H &quot;Content-Type: application/json&quot; https://europe-west4-aiplatform.googleapis.com/v1alpha1/projects/989788194604/locations/europe-west4/endpoints/4614905388473516032:predict -d &quot;{ &quot;instances &quot;: [[1,-0.37078722949973075,-0.09383565010748596,-0.11347464767250347,0.12246106838945217,0.10186437443386016,0.1905715671716009],[2,-0.37078722949973075,-0.09383565010748596,-0.11347464767250347,0.12246106838945217,0.10186437443386016,0.1905715671716009]]}&quot; { &quot;predictions&quot;: [ 8, 8 ], &quot;deployedModelId&quot;: &quot;8016169842207883264&quot;, &quot;model&quot;: &quot;projects/989788194604/locations/europe-west4/models/1804377746017615872&quot;, &quot;modelDisplayName&quot;: &quot;custom-model-uvicorn&quot; } . Batch prediction on Vertex AI . Launching a Batch prediction on Vertex AI with a table including Instance ID (batch_input_data_with_id.csv) on a first column generates now these outputs. Note results are in GCS in the folder prediction-&lt;model-display-name&gt;-&lt;job-create-time&gt;. Inside of it multiple files of type prediction.results-00000-of-000XX: . {&quot;instance&quot;: [26.0, 0.07885108639438881, 0.1464272109727935, 0.1828991258260679, 0.61054018345157, 0.3088025135180327, 0.19057156717160098], &quot;prediction&quot;: 3} {&quot;instance&quot;: [18.0, -0.5506425558573785, -0.539030640110576, -0.542388245344349, -0.12157848914160675, -0.9829072404913923, -0.76127422027253748], &quot;prediction&quot;: 6} {&quot;instance&quot;: [1.0, 0.16877874957321273, 0.20526086240043687, 0.011701852935588793, 1.3426588560447468, 0.28517943828011344, -0.489318281002783638], &quot;prediction&quot;: 3} {&quot;instance&quot;: [25.0, -0.6705461067624772, -0.5936856862810885, -0.5700007087137811, -1.0977367192658425, -1.0452721591194991, -0.62529625063766058], &quot;prediction&quot;: 1} {&quot;instance&quot;: [4.0, -0.4007631172260054, -0.4854167746519732, -0.41168925206237034, 0.12246106838945217, -0.4924921985521885, -0.76127422027253748], &quot;prediction&quot;: 6} {&quot;instance&quot;: [8.0, -0.7005219944887517, -0.6042918471330752, -0.5810456940615539, -1.3417762767969013, -0.9507798581678222, -0.4893182810027836383], &quot;prediction&quot;: 1} {&quot;instance&quot;: [11.0, -0.5506425558573785, -0.4820155843264015, -0.4172117447362567, -0.6096576042037246, -0.12397222484064802, -0.217362341733029828], &quot;prediction&quot;: 6} {&quot;instance&quot;: [5.0, -0.4906907804048293, -0.5117100582300658, -0.4761183332577119, -0.3656180466726657, -0.5917091145514494, -0.62529625063766058], &quot;prediction&quot;: 6} {&quot;instance&quot;: [28.0, 0.8582241672775294, 2.4080799533830155, 2.205972275359794, 0.3665006259205111, 3.2068813837059675, 2.09426314205987748], &quot;prediction&quot;: 7} {&quot;instance&quot;: [2.0, -0.37078722949973075, -0.09383565010748596, -0.11347464767250347, 0.12246106838945217, 0.10186437443386016, 0.19057156717160098], &quot;prediction&quot;: 5} {&quot;instance&quot;: [10.0, -0.3108354540471815, -0.4907476198969507, -0.45955085523605266, -0.3656180466726657, -0.3271306718867537, -0.62529625063766058], &quot;prediction&quot;: 6} {&quot;instance&quot;: [22.0, -0.5506425558573785, -0.5144032456715388, -0.500049134844553, -0.12157848914160675, -0.6200568048369525, -0.489318281002783638], &quot;prediction&quot;: 6} {&quot;instance&quot;: [13.0, -0.6705461067624772, -0.6021956032997636, -0.5681598778224857, -1.0977367192658425, -0.9980260086436606, -0.62529625063766058], &quot;prediction&quot;: 1} . FAQ . Q: 500 Internal server error after POST request: ValueError: [TypeError(&quot;&#39;numpy.int64&#39; object is not iterable&quot;), TypeError(&#39;vars() argument must have __dict__ attribute&#39;)] A: Replace last line of the @app.post handler. Replace return {&quot;predictions&quot;: [item for item in outputs]} with return {&quot;predictions&quot;: outputs.tolist()} | .",
            "url": "https://rafaelsf80.github.io/blog/vertex%20ai/2022/06/15/instance-id-batch-prediction.html",
            "relUrl": "/vertex%20ai/2022/06/15/instance-id-batch-prediction.html",
            "date": " • Jun 15, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "On Token Generation inside Vertex AI Training and Pipelines",
            "content": "Summary . As stated here, Vertex AI Training doesn’t support token generation when using BYOSA. This affects standalone training jobs as well as Vertex AI Pipelines tasks. This includes also calling fetch_id_token() in a Vertex AI Training job. Root cause is that Vertex AI training can not reach the compute metadata service required to retrieve a token. The workaround is to use iamcredentials.googleapis.com. This only happens in Vertex AI single replica training, not in Kubernetes training. . Context . There are two types of tokens (authentication and authorization): . Identity token: (authentication) the identity token is used when calling other Cloud Run services or when invoking any service that can validate an identity token. It used to be fetched from the VM metadata service, and it is included in the Authorization: Bearer header. IAP requires Identity tokens (Cloud IAM) supported by App Engine, GCE, GKE and Cloud Run. For example, identity tokens are retrieved for App Engine using fetch_id_token. | Access token: (authorization) the access token is used for OAuth 2.0 when calling most Google APIs. It used to be fetched from the VM metadata service as well. | . Google’s OAuth 2.0 APIs can be used for both authentication and authorization using the OpenID Connect (OIDC) standard. . To achieve BYOSA (allow running workloads with user’s service account) on GCE training jobs, there are two metadata servers on a GCE VM: . Cloudbuild metadata server: it contains the access token for the user service account. | GCE metadata server. | All the customer’s requests (sending to the GCE metadata server) are redirected to the CloudBuild metadata server for the BYOSA usage, however, that metadata server doesn’t support fetching the identity token. The customer gets a 401 error code. . Calling Cloud Run or Cloud Functions from within Vertex AI Pipelines . Both Cloud Run and Cloud Functions are deployed in private mode by default, protected by Cloud IAM. This means an unauthenticated user can not invoke the service: only an authenticated user with the role roles/run.invoker or roles/cloudfunctions.invoker, respectively, can do it. . To retrieve a token with Cloud IAM inside Vertex AI Pipelines, and overcome the limitation to get a token in Vertex AI Training job, you can use iamcredentials.googleapis.com inside Vertex AI Training. . In the code example, there are two separate service accounts (SAs) in the Vertex AI pipeline (recommended to be different, but could be the same) . SA #1 (pipeline): SA for the pipeline run. | SA #2 (component): SA for service account requesting permissions to access a separate services like Cloud Run, App Engine, … | . First, you use google.auth.default() to get your credentials. Then, there are two HTTP calls: . HTTP call #1: those credentials generate an access token used to call iamcredentials.googleapis.com through the class google.auth.transport.requests.AuthorizedSession (if you sniff the HTTP traffic, that access token is on the Authorization: bearer header). You must set the audience field to the service URL. You need the iam.serviceAccounts.getAccessToken IAM permission on the service account #2. This permission can be granted in the GCP IAM console (for example: the role Cloud Run Service Agent or the role Service Account Token Creator contains that IAM permission) or using gcloud iam service-accounts add-iam-policy-binding with the option --role=roles/iam.serviceAccountTokenCreator. . | HTTP call #2: the previous response contains a new OIDC Token, which is used in the Authorization: bearer to call Cloud Run or Cloud Function service. . | To summarize: you are using one Access Token to create another Access Token (via the iamcredentials.googleapis.com API call) changing identities. But you need the role roles/iam.serviceAccountTokenCreator in the service account to be able to obtain the second Access Token. Additionally, you must add the proper permissions to call other services, like Cloud Run or Cloud Functions (for example: Cloud Run Service Agent to call Cloud Run). . Permissions required for the service account: . roles/iam.serviceAccountTokenCreator | roles/run.invoker or roles/cloudfunctions.invoker, included in Cloud Run Service Agent or Cloud Function Service Agent role. | . import google.cloud.aiplatform as aip from kfp.v2 import compiler from kfp.v2 import dsl from kfp.v2.dsl import (component) project_id = &#39;MY_PROJECT_ID&#39; #&lt;- **CHANGE ME** pipeline_root_path = &#39;gs://BUCKET/FOLDER&#39; #&lt;- **CHANGE ME** template_name = &#39;my_template.json&#39; #&lt;- **CHANGE ME** service_account_pipeline = &#39;debug-token-fetch@MY_PROJECT_ID.iam.gserviceaccount.com&#39; #&lt;- **CHANGE ME** region = &#39;MY_REGION&#39; #&lt;- **CHANGE ME** @component def authed_task(): import google.auth import json from google.auth.transport.requests import AuthorizedSession import urllib service_account_req = &#39;debug-token-fetch@MY_PROJECT_ID.iam.gserviceaccount.com&#39; #&lt;- **CHANGE ME** service_url = &#39;https://my_cloud_run_service&#39; #&lt;- **CHANGE ME** # Gets the access token for service_account. credentials, projectid = google.auth.default() # do credentials.refresh() to guarantee service_account_email is correctly updated # as per https://google-auth.readthedocs.io/en/master/reference/google.auth.compute_engine.credentials.html request = google.auth.transport.requests.Request() credentials.refresh(request) if hasattr(credentials, &quot;service_account_email&quot;): service_account_email_name = credentials.service_account_email print(f&#39;Service account: {service_account_email_name}&#39;) audience = service_url iamcredentials_url = f&#39;https://iamcredentials.googleapis.com/v1/projects/-/serviceAccounts/{service_account_req}:generateIdToken&#39; token_headers = {&#39;content-type&#39;: &#39;application/json&#39;} body = json.dumps({&#39;audience&#39;: audience, &#39;includeEmail&#39;: &#39;TRUE&#39;}) authed_session = AuthorizedSession(credentials) # Requests the identity token from &#39;iamcredentials.googleapis.com&#39; through the access token. token_response = authed_session.request(&#39;POST&#39;, iamcredentials_url, data=body, headers=token_headers).json() print(token_response) oidc_token = token_response[&#39;token&#39;] data = &#39;**Hello Bold Text**&#39; req = urllib.request.Request(service_url, data=data.encode()) req.add_header(&quot;Authorization&quot;, f&quot;Bearer {oidc_token}&quot;) response = urllib.request.urlopen(req) print(&#39;{}&#39;.format(response.read())) @dsl.pipeline( name=&quot;auth-pipeline-cloudrun&quot;, description=&quot;pipeline to debug token fetch.&quot;, pipeline_root=pipeline_root_path ) def debug_auth_pipeline(): debug_out = authed_task() if __name__ == &quot;__main__&quot;: compiler.Compiler().compile( pipeline_func=debug_auth_pipeline, package_path=template_name ) aip.init( project=project_id, location=region, ) job = aip.PipelineJob( display_name=&#39;AuthDebugJobCloudRun&#39;, template_path=template_name, pipeline_root=pipeline_root_path, enable_caching=False, ) job.run(service_account=service_account_pipeline) . Calling App Engine (IAP) from within Vertex AI Pipelines . To retrieve a token for a service behind IAP, like App Engine, you need to fetch the token using fetch_id_token, as described here. However, this fails with a 401 error for the same reason as above due to the limitation to get a token in a Vertex AI Training job. . To overcome the limitation again, you use iamcredentials.googleapis.com inside Vertex AI Training, putting the cliend_id in the audience field. . Permissions required for the service account: . roles/iam.serviceAccountTokenCreator | roles/iap.httpsResourceAccessor, included in IAP-secured Web App User role. | . import google.cloud.aiplatform as aip from kfp.v2 import compiler from kfp.v2 import dsl from kfp.v2.dsl import (component) project_id = &#39;MY_PROJECT_ID&#39; #&lt;- **CHANGE ME** pipeline_root_path = &#39;gs://BUCKET/FOLDER&#39; #&lt;- **CHANGE ME** template_name = &#39;my_template.json&#39; #&lt;- **CHANGE ME** service_account_pipeline = &#39;debug-token-fetch@MY_PROJECT_ID.iam.gserviceaccount.com&#39; #&lt;- **CHANGE ME** region = &#39;MY_REGION&#39; #&lt;- **CHANGE ME** @component def authed_task(): import google.auth import json from google.auth.transport.requests import AuthorizedSession import urllib, requests service_account_req = &#39;debug-token-fetch@MY_PROJECT_ID.iam.gserviceaccount.com&#39; #&lt;- **CHANGE ME** service_url = &#39;https://my_app_engine_service_nehing_iap&#39; #&lt;- **CHANGE ME** # Gets the access token for service_account. credentials, projectid = google.auth.default() # do credentials.refresh() to guarantee service_account_email is correctly updated # as per https://google-auth.readthedocs.io/en/master/reference/google.auth.compute_engine.credentials.html request = google.auth.transport.requests.Request() credentials.refresh(request) if hasattr(credentials, &quot;service_account_email&quot;): service_account_email_name = credentials.service_account_email print(f&#39;Service account: {service_account_email_name}&#39;) audience = &#39;CLIEND_ID&#39; #&lt;- **CHANGE ME** iamcredentials_url = f&#39;https://iamcredentials.googleapis.com/v1/projects/-/serviceAccounts/{service_account_req}:generateIdToken&#39; token_headers = {&#39;content-type&#39;: &#39;application/json&#39;} body = json.dumps({&#39;audience&#39;: audience, &#39;includeEmail&#39;: &#39;TRUE&#39;}) authed_session = AuthorizedSession(credentials) # Requests the identity token from &#39;iamcredentials.googleapis.com&#39; through the access token. token_response = authed_session.request(&#39;POST&#39;, iamcredentials_url, data=body, headers=token_headers).json() oidc_token = token_response[&#39;token&#39;] data = &#39;**Hello Bold Text**&#39; req = urllib.request.Request(service_url, data=data.encode()) req.add_header(&quot;Authorization&quot;, f&quot;Bearer {oidc_token}&quot;) response = urllib.request.urlopen(req) print(&#39;{}&#39;.format(response.read())) @dsl.pipeline( name=&quot;auth-pipeline-iap&quot;, description=&quot;pipeline to debug token fetch.&quot;, pipeline_root=pipeline_root_path ) def debug_auth_pipeline(): debug_out = authed_task() if __name__ == &quot;__main__&quot;: compiler.Compiler().compile( pipeline_func=debug_auth_pipeline, package_path=template_name ) aip.init( project=project_id, location=region, ) job = aip.PipelineJob( display_name=&#39;AuthDebugJobCloudRun&#39;, template_path=template_name, pipeline_root=pipeline_root_path, enable_caching=False, ) job.run(service_account=service_account_pipeline) . Notes . As per public SDK docs of google.auth, the method google.auth.default() gets credentials differently is you are launching from local or from within a cloud service (App Engine, GCE, Vertex, …). For execution in Vertex AI, credentials are obtained from the metadata service (see section 4 in the docs). However, if local, credentials are obtained from either GOOGLE_APPLICATION_CREDENTIALS or gcloud SDK (see sections 1-2). | As per public SDK docs of google.auth.compute_engine.credentials.Credentials, it is stated that the service_account_email field is not guaranteed until a refresh() is done. In case you get the string default instead of a valid email service account, make sure you call refresh(). py credentials, projectid = google.auth.default() | . request = google.auth.transport.requests.Request() credentials.refresh(request) . if hasattr(credentials, “service_account_email”): service_account_email_name = credentials.service_account_email print(f’Service account: {service_account_email_name}’) . In case you launch the code locally, not in Vertex AI, you must: 1) Use a JSON key and point it to GOOGLE_APPLICATION_CREDENTIALS; 2) Make sure you add auth scopes when calling google.auth.default: credentials, projectid = google.auth.default(scopes=[&#39;https://www.googleapis.com/auth/cloud-platform&#39;]) | . References . [1] Authentication from a service acoount to an IAP-web service [2] Medium article on Securing Cloud Run, Cloud Functions and App Engine with an API key [3] https://stackoverflow.com/questions/67640123/how-to-protect-app-hosted-on-google-cloud-run .",
            "url": "https://rafaelsf80.github.io/blog/vertex%20ai/2022/05/31/token-vertex-pipelines.html",
            "relUrl": "/vertex%20ai/2022/05/31/token-vertex-pipelines.html",
            "date": " • May 31, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "On AutoML Translate and BLEU",
            "content": "Summary . When evaluating a new test set with AutoML Translate, it can only be done through the UI, and not with the API. Refer to [here] on how BLEU works. Note the calculation m ay defer if using the open-source tool and the method nltk.translate.bleu_score_corpus_bleu, due to the fact that normalization and tokenization may defer. . So, to avoid misunderstanding between the open source NLTK tool and the internal BLEU scaore calculation in AutoML, use always the NLTK to evaluate. . Code example . import nltk hypothesis = [&#39;This&#39;, &#39;is&#39;, &#39;cat&#39;] reference = [&#39;This&#39;, &#39;is&#39;, &#39;a&#39;, &#39;cat&#39;] references = [reference] # list of references for 1 sentence. list_of_references = [references] # list of references for all sentences in corpus. list_of_hypotheses = [hypothesis] # list of hypotheses that corresponds to list of references. nltk.translate.bleu_score.corpus_bleu(list_of_references, list_of_hypotheses) # 0.6025286104785453 nltk.translate.bleu_score.sentence_bleu(references, hypothesis) # 0.6025286104785453 . References . [1] Understanding the BLEU Score .",
            "url": "https://rafaelsf80.github.io/blog/vertex%20ai/2022/05/31/automl-translate-bleu.html",
            "relUrl": "/vertex%20ai/2022/05/31/automl-translate-bleu.html",
            "date": " • May 31, 2022"
        }
        
    
  
    
        ,"post4": {
            "title": "The purity metric in a clustering algorithm",
            "content": "1. Introducci&#243;n . Este ejemplo muestra cómo hacer un agrupamiento (clustering) para el dataset de de imágenes de Cifar-10. Nótese que esto no es un problema de clasificación, sino un clustering con un tipo de entrenamiento NO supervisado. . Diferencias entre clasificación y agrupamiento ó clustering: . En la clasificación, las clases resultantes son dadas como parte del set de entrenamiento. Esta información es realmente usada durante el entrenamiento apra construir el clasificador. Posteriormente, se aplica el clasificador resultante sobre imágenes nuevas (sin clasificar previamente). | En el agrupamiento, se particionan las imágenes en varios grupos (clases resultantes). No se conoce el significado de esas clases,simplemente se sabe que estadísticamente son parecidas. Ejemplos de redes para clasificación es una red convolucional (aprendizaje supervisado). Ejemplo de algoritmos de agrupamiento es kMeans. | . En este notebook se va a usar k-Means, que es un algoritmo de clasificación no supervisado (clustering) que agrupa objetos en k grupos basándose en sus características. El clustering in k grupos se realiza minimizando la suma de distancias (puede ser media ó cuadrática) entre cada objeto y el centroide de su cluster. . Este ejemplo se ha probado y funciona en Colab. . 2. Setup . Importamos las librerías que vamos a usar. Usaremos la función experimental tensorflow.numpy para aprovechar las GPUs durante operaciones con funciones numpy (por ejemplo, durante la inferencia): . !pip3 install --user --upgrade tf-nightly !pip3 install --user scikit-learn . import matplotlib.pyplot as plt import tensorflow as tf import numpy as np from sklearn.utils import shuffle from tensorflow.keras import datasets, layers, models . Comprobamos si tenemos GPUs. En caso contrario, no notaremos diferencia de velocidad: . print(&quot;All logical devices:&quot;, tf.config.list_logical_devices()) print(&quot;All physical devices:&quot;, tf.config.list_physical_devices()) print(&quot;Num GPUs Available: &quot;, len(tf.config.experimental.list_physical_devices(&#39;GPU&#39;))) . All logical devices: [LogicalDevice(name=&#39;/device:CPU:0&#39;, device_type=&#39;CPU&#39;)] All physical devices: [PhysicalDevice(name=&#39;/physical_device:CPU:0&#39;, device_type=&#39;CPU&#39;)] Num GPUs Available: 0 . 3. Carga de datos . Cargamos el dataset desde tensorflow.keras.datasets: . (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data() # Usando scikit-learn, Hacemos shuffle y usamos sólo 2000 imágenes para entrenar y 100 para test train_images, train_labels = shuffle(train_images, train_labels) test_images, test_labels = shuffle(test_images, test_labels) train_images = train_images[:2000] train_labels = train_labels[:2000] test_images = test_images[:100] test_labels = test_labels[:100] # Normalizamos valores de píxeles entre 0 y 1 train_images, test_images = train_images / 255.0, test_images / 255. . Visualizamos los primeros 25 elementos del dataset: . class_names = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;] plt.figure(figsize=(10,10)) for i in range(25): plt.subplot(5,5,i+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(train_images[i], cmap=plt.cm.binary) # The CIFAR labels happen to be arrays, # which is why you need the extra index plt.xlabel(class_names[train_labels[i][0]]) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:12:48.343799 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ 4. Preparar datos . El set de entrenamiento original era de tamaño train_images.shape=(50000,32,32,3) y sus etiquetas train_labels.shape=(50000, 1). Pero usamos uno más pequeño de 2000. Aplanamos el set de entrenamiento y también el de pruebas: . train_images_rows = train_images.reshape(train_images.shape[0], 32 * 32 * 3) # train_images_rows.shape 2000 x 3072 test_images_rows = test_images.reshape(test_images.shape[0], 32 * 32 * 3) # test_images_rows.shape 100 x 3072 . 5. Construcci&#243;n del modelo . El algoritmo k-Means consta de tres pasos: . Inicialización: se selecciona el número de centroides (grupos, NUM_CENTROIDS) y se crean con el tamaño de las imágenes, aleatorios. | Asignación: cada imagen es asignada a su centroide más cercano. | Actualización centroides: se actualiza la posición del centroide de cada grupo tomando como nuevo centroide la posición del promedio de los objetos pertenecientes a dicho grupo. | Se repiten los pasos 2 y 3 hasta que los centroides no cambian. . Para medir la precisión, se usa la métrica Purity, que es una medida de evaluación muy sencilla y transparente, en donde se cuenta la etiqueta más frecuente en cada cluster, y se calcula la pureza dividiendo ese valor por el número total de elementos del cluster. La pureza del algoritmo es simplemente la suma de las purezas de cada cluster. En el mejor caso, para un cluster de 10 centroides, la pureza debería ser 10 (NUM_CENTROIDS). Una definición más formal de pureza se puede ver aqui(Stanford), donde define la pureza (purity) de la siguiente manera: . To compute purity , each cluster is assigned to the class which is most frequent in the cluster, and then the accuracy of this assignment is measured by counting the number of correctly assigned documents and dividing by N. . # Paso 1: Inicialización NUM_IMAGES = train_images.shape[0] # 2000 NUM_CENTROIDS = 10 # We know number of centroids beforehand # Paso 2: Asignación a centroide más cercano def assignment(centroids): closest = [] for j in range(NUM_IMAGES): distances_from_centroid = [] for i in range(NUM_CENTROIDS): distances_from_centroid = np.append(distances_from_centroid, np.sum(np.abs(centroids[i, :] - train_images_rows[j,:]))) #print(distances_from_centroid) closest.append(np.argmin(distances_from_centroid)) #print(closest) return closest # Paso 3: Actualización centroides def update(closest): purity = [] new_centroids = np.zeros((NUM_CENTROIDS, 32*32*3)) for c in range(NUM_CENTROIDS): num = 0 # num of IMAGES in the cluster best = [] # Takes all images assigned to the centroid and calculates average for i in range(NUM_IMAGES): if (closest[i] == c): num = num + 1 #print(train_images_rows[i, :]) new_centroids[c, :] += train_images_rows[i, :] best = np.append(best, train_labels[i]) # Discard if there are no images (num=0) assigned to a centroid # Calculate average if (num&gt;0): new_centroids[c, :] = new_centroids[c, :] / num # Calculate PURITY for each cluster separately # Note clusters do not follow label ordering of train images, so cluster 0 does not equal to label_0 (airplane) unique, counts = np.unique(best, return_counts=True) #print(&quot;Cluster &quot;, c ,&quot; has &quot;, num, &quot; images assigned. Most frequent label is: &quot;, unique[counts == counts.max()]) #print(dict(zip(unique, counts))) correct_label_count = 0 # Fix case where two or more labels are the most frequent in a cluster simultaneously if (unique[counts == counts.max()].size &gt; 1): best_label = unique[counts == counts.max()][0] else: best_label = unique[counts == counts.max()] # Calculate accuracy of each cluster for i in range(NUM_IMAGES): if (closest[i] == c): if (best_label != train_labels[i]): correct_label_count += 1 purity = np.append(purity, correct_label_count/num) return new_centroids, purity . # Ejecución del algoritmo k-Means: bucle hasta que los centroides no cambian centroides = np.random.rand(NUM_CENTROIDS, 32*32*3) while True: cercanos = assignment(centroides) nuevos_centroides, pureza = update(cercanos) print(&quot;Purity: &quot;, np.sum(pureza), &quot; Centroids convergence: &quot;, np.sum(nuevos_centroides)-np.sum(centroides)) if (np.allclose(nuevos_centroides, centroides)): break centroides = nuevos_centroides . Purity: 8.143573240427953 Centroids convergence: -1011.9732804228533 Purity: 8.117762662055938 Centroids convergence: 74.80783684575181 Purity: 7.915912560407891 Centroids convergence: 121.73650328388248 Purity: 7.796077104366344 Centroids convergence: 92.51681301552344 Purity: 7.7482000340978505 Centroids convergence: 99.12812322555874 Purity: 7.6869370898431315 Centroids convergence: 65.22459724608962 Purity: 7.622074432728336 Centroids convergence: 40.922291395248976 Purity: 7.603127348295604 Centroids convergence: 42.50720856783482 Purity: 7.6029885866448135 Centroids convergence: 35.76182789657105 Purity: 7.586641777683099 Centroids convergence: 20.81112928343464 Purity: 7.578510156816363 Centroids convergence: 9.413361443677786 Purity: 7.587036260912649 Centroids convergence: 13.923756300480818 Purity: 7.590103527738729 Centroids convergence: 12.267108683232436 Purity: 7.573613677399101 Centroids convergence: 13.31292766352999 Purity: 7.5810286257399815 Centroids convergence: 11.1740192087982 Purity: 7.584263425481467 Centroids convergence: 12.531641388104617 Purity: 7.583250467666781 Centroids convergence: 8.272761105219615 Purity: 7.5942143516161495 Centroids convergence: 12.022298838617644 Purity: 7.586518825764817 Centroids convergence: 3.870052221696824 Purity: 7.586031829046814 Centroids convergence: 2.3619532464254007 Purity: 7.5854165899455435 Centroids convergence: 5.006124093717517 Purity: 7.58502887424958 Centroids convergence: 3.0531509890861344 Purity: 7.584230071156004 Centroids convergence: 2.689206672284854 Purity: 7.584077839949038 Centroids convergence: 1.1983034891727584 Purity: 7.583391882373221 Centroids convergence: 1.8873040262260474 Purity: 7.57875427949938 Centroids convergence: -0.31221975871449104 Purity: 7.57141359323422 Centroids convergence: 6.717176250793273 Purity: 7.570639863543898 Centroids convergence: 1.6986865756844054 Purity: 7.558790402858739 Centroids convergence: 2.8300456869510526 Purity: 7.5666057351014855 Centroids convergence: 5.180336900644761 Purity: 7.566982556559942 Centroids convergence: 1.7703563416289398 Purity: 7.566982556559942 Centroids convergence: 0.0 . En el paso 2 anterior (asignación de centroides), se puede usar la distancia L1 ó L2 (cuadrática). Para la diferencia cuadrática, simplemente cambiar la línea por la siguiente: distances_from_centroid.append(np.sqrt(np.sum(np.abs(centroids[i, :] - train_images_rows[j,:])))) . 6. Evaluaci&#243;n . La pureza (purity) la obtuvimos en el paso anterior. Cada cluster no sigue el orden de las etiquetas del dataset, es decir, el cluster 0 no corresponde a la clase airplane. Mostramos las 25 primeras imágenes del Cluster 0, aunque esto no es representativo ya que la precisión es baja y no estamos viendo todas las imágenes del cluster 0: . CENTROID_TO_EVALUATE = 0 # Cluster a mostrar train_images_rows_img = train_images_rows.reshape(train_images_rows.shape[0], 32, 32, 3) plt.figure(figsize=(10,10)) num = 0 for i in range(NUM_IMAGES): if (num == 25): break if (cercanos[i] == CENTROID_TO_EVALUATE): plt.subplot(5,5,num+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(train_images_rows_img[i], cmap=plt.cm.binary) plt.xlabel(cercanos[i]) num += 1 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:13:08.355791 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Como curiosidad, vemos los 10 centroides generados y mostramos sus imágenes: . centroides_img = nuevos_centroides.reshape(nuevos_centroides.shape[0], 32, 32, 3) plt.figure(figsize=(10,10)) for c in range(NUM_CENTROIDS): plt.subplot(5,5,c+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(centroides_img[c], cmap=plt.cm.binary) # The CIFAR labels happen to be arrays, # which is why you need the extra index plt.xlabel(c) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:13:11.155897 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ 7. Comprobaci&#243;n con scikit-learn . Vamos a comprobar el resultado y la calcular la pureza (purity) con la librería scikit-learn, usando la clase sklearn.cluster.KMeans, para compararla con nuestro resultado anterior . from sklearn.cluster import KMeans n = 10 k_means = KMeans(n_clusters=n) k_means.fit(train_images_rows) . KMeans(n_clusters=10) . centroids = k_means.cluster_centers_ labels= k_means.labels_ . Z = k_means.predict(train_images_rows) purity = 0 best = [] for i in range(0,n): row = np.where(Z==i)[0] # row in Z for elements of cluster i num = row.shape[0] # number of elements for each cluster r = np.floor(num/10.) # number of rows in the figure of the cluster print(&quot;Cluster &quot;+str(i)+&quot; has &quot;+str(num)+&quot; elements&quot;) plt.figure(figsize=(10,10)) for k in range(0, num): plt.subplot(r+1, 10, k+1) image = train_images_rows[row[k], ] image = image.reshape(32, 32, 3) plt.imshow(image, cmap=&#39;gray&#39;) plt.axis(&#39;off&#39;) best = np.append(best, train_labels[row[k]]) unique, counts = np.unique(best, return_counts=True) #print(str(counts.max())+&quot; out of &quot;+str(num)) purity += counts.max()/num print(&quot;Purity: &quot;+str(purity)) plt.show() . Cluster 0 has 194 elements Purity: 0.22164948453608246 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:13:21.549469 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 1 has 207 elements Purity: 0.525997310623039 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:13:30.297551 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 2 has 273 elements Purity: 0.8776456622713906 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:13:41.986646 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 3 has 169 elements Purity: 1.6113734729222782 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:13:49.847821 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 4 has 113 elements Purity: 2.806063738409004 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:13:54.986668 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 5 has 177 elements Purity: 3.591374472872281 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:14:02.281463 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 6 has 161 elements Purity: 4.541685031878492 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:14:09.478339 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 7 has 288 elements Purity: 5.159740587434047 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:14:20.742189 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 8 has 196 elements Purity: 6.175046709883027 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:14:29.637466 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ Cluster 9 has 222 elements Purity: 7.161533196369514 . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-02T23:14:39.156964 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/",
            "url": "https://rafaelsf80.github.io/blog/computer%20vision/2020/10/15/cifar-kmeans.html",
            "relUrl": "/computer%20vision/2020/10/15/cifar-kmeans.html",
            "date": " • Oct 15, 2020"
        }
        
    
  
    
        ,"post5": {
            "title": "Optimization with tf.numpy, tf.function and tf.vectorized_map",
            "content": "1. Introducci&#243;n . Este ejemplo muestra cómo hacer una clasificación de imágenes usando Machine Learning clásico, sin usar una red convolucional. Se va a usar k-Nearest Neighbor (k=1 en este notebook) y una precisión básica basada en diferencia de pixels. Usaremos la función experimental tensorflow.numpy para aprovechar las GPUs durante operaciones con funciones numpy (por ejemplo, durante la inferencia). Instrucciones originales de kNN tomadas del curso de Stanford CS231. . 2. Setup . Importamos las librerías que vamos a usar: . !pip3 install --user --quiet --upgrade tf-nightly . ERROR: tensorflow 2.3.1 has requirement gast==0.3.3, but you&#39;ll have gast 0.4.0 which is incompatible. ERROR: tensorflow 2.3.1 has requirement h5py&lt;2.11.0,&gt;=2.10.0, but you&#39;ll have h5py 3.1.0 which is incompatible. ERROR: tensorflow 2.3.1 has requirement numpy&lt;1.19.0,&gt;=1.16.0, but you&#39;ll have numpy 1.19.4 which is incompatible. WARNING: The script tensorboard is installed in &#39;/Users/rafaelsanchez/Library/Python/3.8/bin&#39; which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in &#39;/Users/rafaelsanchez/Library/Python/3.8/bin&#39; which is not on PATH. Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location. WARNING: You are using pip version 19.2.3, however version 20.3.3 is available. You should consider upgrading via the &#39;pip install --upgrade pip&#39; command. . import matplotlib.pyplot as plt from sklearn.utils import shuffle import tensorflow as tf import tensorflow.experimental.numpy as tnp from tensorflow.keras import datasets, layers, models import timeit . ImportError Traceback (most recent call last) &lt;ipython-input-7-1920e3b402dc&gt; in &lt;module&gt; 4 5 import tensorflow as tf -&gt; 6 import tensorflow.experimental.numpy as tnp 7 from tensorflow.keras import datasets, layers, models 8 ~/Library/Python/3.8/lib/python/site-packages/tensorflow/_api/v2/experimental/numpy/__init__.py in &lt;module&gt; 156 import sys as _sys 157 --&gt; 158 from . import random 159 from tensorflow.python.ops.numpy_ops import issubdtype 160 from tensorflow.python.ops.numpy_ops import max ~/Library/Python/3.8/lib/python/site-packages/tensorflow/_api/v2/experimental/numpy/random/__init__.py in &lt;module&gt; 8 import sys as _sys 9 &gt; 10 from tensorflow.python.ops.numpy_ops.np_random import poisson 11 from tensorflow.python.ops.numpy_ops.np_random import rand 12 from tensorflow.python.ops.numpy_ops.np_random import randint ImportError: cannot import name &#39;poisson&#39; from &#39;tensorflow.python.ops.numpy_ops.np_random&#39; (/Users/rafaelsanchez/Library/Python/3.8/lib/python/site-packages/tensorflow/python/ops/numpy_ops/np_random.py) . Comprobamos si tenemos GPUs. En caso contrario, no notaremos diferencia de velocidad: . print(&quot;All logical devices:&quot;, tf.config.list_logical_devices()) print(&quot;All physical devices:&quot;, tf.config.list_physical_devices()) print(&quot;Num GPUs Available: &quot;, len(tf.config.experimental.list_physical_devices(&#39;GPU&#39;))) . All logical devices: [LogicalDevice(name=&#39;/device:CPU:0&#39;, device_type=&#39;CPU&#39;), LogicalDevice(name=&#39;/device:XLA_CPU:0&#39;, device_type=&#39;XLA_CPU&#39;)] All physical devices: [PhysicalDevice(name=&#39;/physical_device:CPU:0&#39;, device_type=&#39;CPU&#39;), PhysicalDevice(name=&#39;/physical_device:XLA_CPU:0&#39;, device_type=&#39;XLA_CPU&#39;)] Num GPUs Available: 0 . 3. Carga de datos . Cargamos el dataset desde tensorflow.keras.datasets: . (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data() # Usando scikit-learn, Hacemos shuffle y usamos sólo 2000 imágenes para entrenar y 100 para test train_images, train_labels = shuffle(train_images, train_labels) test_images, test_labels = shuffle(test_images, test_labels) train_images = train_images[:2000] train_labels = train_labels[:2000] test_images = test_images[:100] test_labels = test_labels[:100] # Normalizamos valores de píxeles entre 0 y 1 train_images, test_images = train_images / 255.0, test_images / 255. . NameError Traceback (most recent call last) &lt;ipython-input-5-278cce811302&gt; in &lt;module&gt; -&gt; 1 (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data() 2 3 # Usando scikit-learn, Hacemos shuffle y usamos sólo 2000 imágenes para entrenar y 100 para test 4 train_images, train_labels = shuffle(train_images, train_labels) 5 test_images, test_labels = shuffle(test_images, test_labels) NameError: name &#39;datasets&#39; is not defined . Visualizamos los primeros 25 elementos del dataset: . class_names = [&#39;airplane&#39;, &#39;automobile&#39;, &#39;bird&#39;, &#39;cat&#39;, &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;] plt.figure(figsize=(10,10)) for i in range(25): plt.subplot(5,5,i+1) plt.xticks([]) plt.yticks([]) plt.grid(False) plt.imshow(train_images[i], cmap=plt.cm.binary) # The CIFAR labels happen to be arrays, # which is why you need the extra index plt.xlabel(class_names[train_labels[i][0]]) plt.show() . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt; 2020-11-17T13:43:49.500706 image/svg+xml Matplotlib v3.3.2, https://matplotlib.org/ 4. Preparar datos . El set de entrenamiento original era de tamaño train_images.shape=(50000,32,32,3) y sus etiquetas train_labels.shape=(50000, 1). Pero usamos uno más pequeño de 2000. Aplanamos el set de entrenamiento y también el de pruebas: . train_images_rows = train_images.reshape(train_images.shape[0], 32 * 32 * 3) # train_images_rows.shape 2000 x 3072 test_images_rows = test_images.reshape(test_images.shape[0], 32 * 32 * 3) # test_images_rows.shape 100 x 3072 . 5. Construcci&#243;n del modelo . Para la predicción, se compara una imagen de test con todas las de entrenamiento, y se devuelve la de menor diferencia (distancia L1: resta de valores de pixels). Usamos k=1 (es decir, sólo el vecino más cercano) de kNN. Con un k superior, pej k=5 compararíamos con 5 imágenes y se devolvería la etiqueta más común de las 5. . class NearestNeighbor(object): def __init__(self): pass def train(self, X, y): &quot;&quot;&quot; X is N x D where each row is an example. Y is 1-dimension of size N &quot;&quot;&quot; # the nearest neighbor classifier simply remembers all the training data self.Xtr = tnp.array(X) self.ytr = tnp.array(y) def predict(self, X): &quot;&quot;&quot; X is N x D where each row is an example we wish to predict label for &quot;&quot;&quot; num_test = X.shape[0] # lets make sure that the output type matches the input type Ypred = tnp.zeros(0, dtype = self.ytr.dtype) # loop over all test rows for i in range(num_test): # find the nearest training image to the i&#39;th test image # using the L1 distance (sum of absolute value differences) distances = tnp.sum(tnp.abs(self.Xtr - X[i,:]), axis = 1) min_index = tnp.argmin(distances) # get the index with smallest distance Ypred = tnp.append(Ypred, self.ytr[min_index]) # predict the label of the nearest example #print(&quot;Test image {} of {} is {}&quot;.format(i, num_test, Ypred[-1])) return Ypred . Para la predicción, se puede usar la distancia L1 ó L2 (cuadrática). Para la diferencia cuadrática, simplemente cambiar la lína anterior por la siguiente: distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1)) . 6. Entrenamiento y evaluaci&#243;n. Medida con timeit . Lanzamos el entrenamiento usando k Nearest Neighbors (kNN), con k=1. Para la predicción, se calcula la menor diferencia entre la imagen del set de prueba y todas las imágenes de entrenamiento. Se devuelve la etiqueta de la de menor diferencia. Medimos la velocidad de tensorflow.experimental.numpy con timeit. Para comparar la velocidad entre tensorflow.experimental.numpy (lo que medimos) y numpy, hay que cambiar el import de las primeras celdas y ejecutar el notebook de nuevo. . nn = NearestNeighbor() # create a Nearest Neighbor classifier class %timeit nn.train(train_images_rows, train_labels) # train the classifier on the training images and labels %timeit nn.predict(test_images_rows) . 141 µs ± 28.5 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 3.06 s ± 59 ms per loop (mean ± std. dev. of 7 runs, 1 loop each) . Yte_predict = nn.predict(test_images_rows) Yte_predict = Yte_predict.reshape(100,1) print(&#39;Accuracy: %f&#39; % ( tnp.mean( tnp.array(Yte_predict) == test_labels) )) . Accuracy: 0.250000 . 7. Optimizaciones con tf.function y tf.vectorized_map . tf.function se puede usar como pre-compilador de trazas para ejecutar código más rápido en TensorFlow. Además, se puede usar en combinación con tf.experimental.numpy para acelerar aún más. Nótese que tf.function llama a tf.experimental.numpy (no a numpy), y que espera ND arrays como entradas y salidas. Es decir, todas las operaciones dentro de la función compilada deben usar tensorflow.experimental.numpy mientras que las entradas y salidas podrían ser numpy. Más información aqui. . tf.vectorized_map permite paralelizar operaciones y evitar bucles. Funciona con numpy y tf.numpy. Más información aqui . Ambas optimizaciones están disponibles desde TensorFlow 2.4. . print(&quot;Eager performance&quot;) Yte_predict = nn.predict(test_images_rows) print(timeit.timeit(lambda: nn.predict(test_images_rows), number=10)* 100, &quot;ms&quot;) print(&quot; ntf.function compiled performance&quot;) compiled_predict = tf.function(nn.predict) compiled_predict(test_images_rows) # warmup print(timeit.timeit(lambda: compiled_predict(test_images_rows), number=10) * 100, &quot;ms&quot;) print(&quot; ntf.vectorized_map performance&quot;) Xtr = tnp.array(train_images_rows) ytr = tnp.array(train_labels) @tf.function def vectorized_predict(inputs): def single_example_predict(arg): inp = arg distances = tnp.sum(tnp.abs(Xtr - inp)) min_index = tnp.argmin(distances) # get the index with smallest distance # Ypred = ytr[min_index] # predict the label of the nearest example Ypred = tf.gather(ytr, min_index) # avoids strided_slice warning return Ypred return tf.vectorized_map(single_example_predict, (inputs)) print(timeit.timeit(lambda: vectorized_predict(test_images_rows), number=10) * 100, &quot;ms&quot;) . Eager performance 3166.1359351999636 ms tf.function compiled performance 1640.888931399968 ms tf.vectorized_map performance WARNING:tensorflow:Using a while_loop for converting StridedSlice 2714.0616581999893 ms .",
            "url": "https://rafaelsf80.github.io/blog/computer%20vision/2020/10/01/cifar-knn.html",
            "relUrl": "/computer%20vision/2020/10/01/cifar-knn.html",
            "date": " • Oct 1, 2020"
        }
        
    
  
    
        ,"post6": {
            "title": "Using keras.mixed_precission",
            "content": "This tutorial focuses on the task of image segmentation, using a modified U-Net. . What is image segmentation? . So far you have seen image classification, where the task of the network is to assign a label or class to an input image. However, suppose you want to know where an object is located in the image, the shape of that object, which pixel belongs to which object, etc. In this case you will want to segment the image, i.e., each pixel of the image is given a label. Thus, the task of image segmentation is to train a neural network to output a pixel-wise mask of the image. This helps in understanding the image at a much lower level, i.e., the pixel level. Image segmentation has many applications in medical imaging, self-driving cars and satellite imaging to name a few. . The dataset that will be used for this tutorial is the Oxford-IIIT Pet Dataset, created by Parkhi et al. The dataset consists of images, their corresponding labels, and pixel-wise masks. The masks are basically labels for each pixel. Each pixel is given one of three categories : . Class 1 : Pixel belonging to the pet. | Class 2 : Pixel bordering the pet. | Class 3 : None of the above/ Surrounding pixel. | . !pip install git+https://github.com/tensorflow/examples.git !pip install -U tfds-nightly . import tensorflow as tf . from tensorflow_examples.models.pix2pix import pix2pix import tensorflow_datasets as tfds tfds.disable_progress_bar() from IPython.display import clear_output import matplotlib.pyplot as plt !nvidia-smi -L from tensorflow.keras.mixed_precision import experimental as mixed_precision policy = mixed_precision.Policy(&#39;mixed_float16&#39;) mixed_precision.set_policy(policy) . Download the Oxford-IIIT Pets dataset . The dataset is already included in TensorFlow datasets, all that is needed to do is download it. The segmentation masks are included in version 3+. . dataset, info = tfds.load(&#39;oxford_iiit_pet:3.*.*&#39;, with_info=True) . if tf.config.list_physical_devices(&#39;GPU&#39;): print(&#39;The model will run with 4096 units on a GPU&#39;) num_units = 4096 else: # Use fewer units on CPUs so the model finishes in a reasonable amount of time print(&#39;The model will run with 64 units on a CPU&#39;) num_units = 64 . The following code performs a simple augmentation of flipping an image. In addition, image is normalized to [0,1]. Finally, as mentioned above the pixels in the segmentation mask are labeled either {1, 2, 3}. For the sake of convenience, let&#39;s subtract 1 from the segmentation mask, resulting in labels that are : {0, 1, 2}. . def normalize(input_image, input_mask): input_image = tf.cast(input_image, tf.float32) / 255.0 input_mask -= 1 return input_image, input_mask . @tf.function def load_image_train(datapoint): input_image = tf.image.resize(datapoint[&#39;image&#39;], (128, 128)) input_mask = tf.image.resize(datapoint[&#39;segmentation_mask&#39;], (128, 128)) if tf.random.uniform(()) &gt; 0.5: input_image = tf.image.flip_left_right(input_image) input_mask = tf.image.flip_left_right(input_mask) input_image, input_mask = normalize(input_image, input_mask) return input_image, input_mask . def load_image_test(datapoint): input_image = tf.image.resize(datapoint[&#39;image&#39;], (128, 128)) input_mask = tf.image.resize(datapoint[&#39;segmentation_mask&#39;], (128, 128)) input_image, input_mask = normalize(input_image, input_mask) return input_image, input_mask . The dataset already contains the required splits of test and train and so let&#39;s continue to use the same split. . TRAIN_LENGTH = info.splits[&#39;train&#39;].num_examples BATCH_SIZE = 64 BUFFER_SIZE = 1000 STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE . train = dataset[&#39;train&#39;].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE) test = dataset[&#39;test&#39;].map(load_image_test) . train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat() train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE) test_dataset = test.batch(BATCH_SIZE) . Let&#39;s take a look at an image example and it&#39;s correponding mask from the dataset. . def display(display_list): plt.figure(figsize=(15, 15)) title = [&#39;Input Image&#39;, &#39;True Mask&#39;, &#39;Predicted Mask&#39;] for i in range(len(display_list)): plt.subplot(1, len(display_list), i+1) plt.title(title[i]) plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i])) plt.axis(&#39;off&#39;) plt.show() . for image, mask in train.take(1): sample_image, sample_mask = image, mask display([sample_image, sample_mask]) . Define the model . The model being used here is a modified U-Net. A U-Net consists of an encoder (downsampler) and decoder (upsampler). In-order to learn robust features, and reduce the number of trainable parameters, a pretrained model can be used as the encoder. Thus, the encoder for this task will be a pretrained MobileNetV2 model, whose intermediate outputs will be used, and the decoder will be the upsample block already implemented in TensorFlow Examples in the Pix2pix tutorial. . The reason to output three channels is because there are three possible labels for each pixel. Think of this as multi-classification where each pixel is being classified into three classes. . OUTPUT_CHANNELS = 3 . As mentioned, the encoder will be a pretrained MobileNetV2 model which is prepared and ready to use in tf.keras.applications. The encoder consists of specific outputs from intermediate layers in the model. Note that the encoder will not be trained during the training process. . base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False) # Use the activations of these layers layer_names = [ &#39;block_1_expand_relu&#39;, # 64x64 &#39;block_3_expand_relu&#39;, # 32x32 &#39;block_6_expand_relu&#39;, # 16x16 &#39;block_13_expand_relu&#39;, # 8x8 &#39;block_16_project&#39;, # 4x4 ] layers = [base_model.get_layer(name).output for name in layer_names] # Create the feature extraction model down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers) down_stack.trainable = False . The decoder/upsampler is simply a series of upsample blocks implemented in TensorFlow examples. . up_stack = [ pix2pix.upsample(512, 3), # 4x4 -&gt; 8x8 pix2pix.upsample(256, 3), # 8x8 -&gt; 16x16 pix2pix.upsample(128, 3), # 16x16 -&gt; 32x32 pix2pix.upsample(64, 3), # 32x32 -&gt; 64x64 ] . def unet_model(output_channels): inputs = tf.keras.layers.Input(shape=[128, 128, 3]) x = inputs # Downsampling through the model skips = down_stack(x) x = skips[-1] skips = reversed(skips[:-1]) # Upsampling and establishing the skip connections for up, skip in zip(up_stack, skips): x = up(x) concat = tf.keras.layers.Concatenate() x = concat([x, skip]) # This is the last layer of the model last = tf.keras.layers.Conv2DTranspose( output_channels, 3, strides=2, padding=&#39;same&#39;) #64x64 -&gt; 128x128 x = last(x) return tf.keras.Model(inputs=inputs, outputs=x) . Train the model . Now, all that is left to do is to compile and train the model. The loss being used here is losses.SparseCategoricalCrossentropy(from_logits=True). The reason to use this loss function is because the network is trying to assign each pixel a label, just like multi-class prediction. In the true segmentation mask, each pixel has either a {0,1,2}. The network here is outputting three channels. Essentially, each channel is trying to learn to predict a class, and losses.SparseCategoricalCrossentropy(from_logits=True) is the recommended loss for such a scenario. Using the output of the network, the label assigned to the pixel is the channel with the highest value. This is what the create_mask function is doing. . model = unet_model(OUTPUT_CHANNELS) model.compile(optimizer=&#39;adam&#39;, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[&#39;accuracy&#39;]) . Have a quick look at the resulting model architecture: . tf.keras.utils.plot_model(model, show_shapes=True) . Let&#39;s try out the model to see what it predicts before training. . def create_mask(pred_mask): pred_mask = tf.argmax(pred_mask, axis=-1) pred_mask = pred_mask[..., tf.newaxis] return pred_mask[0] . def show_predictions(dataset=None, num=1): if dataset: for image, mask in dataset.take(num): pred_mask = model.predict(image) display([image[0], mask[0], create_mask(pred_mask)]) else: display([sample_image, sample_mask, create_mask(model.predict(sample_image[tf.newaxis, ...]))]) . show_predictions() . Let&#39;s observe how the model improves while it is training. To accomplish this task, a callback function is defined below. . class DisplayCallback(tf.keras.callbacks.Callback): def on_epoch_end(self, epoch, logs=None): clear_output(wait=True) show_predictions() print (&#39; nSample Prediction after epoch {} n&#39;.format(epoch+1)) . EPOCHS = 20 VAL_SUBSPLITS = 5 VALIDATION_STEPS = info.splits[&#39;test&#39;].num_examples//BATCH_SIZE//VAL_SUBSPLITS import time start = time.time() model_history = model.fit(train_dataset, epochs=EPOCHS, steps_per_epoch=STEPS_PER_EPOCH, validation_steps=VALIDATION_STEPS, validation_data=test_dataset, callbacks=[DisplayCallback()]) end = time.time() print(end - start) . loss = model_history.history[&#39;loss&#39;] val_loss = model_history.history[&#39;val_loss&#39;] epochs = range(EPOCHS) plt.figure() plt.plot(epochs, loss, &#39;r&#39;, label=&#39;Training loss&#39;) plt.plot(epochs, val_loss, &#39;bo&#39;, label=&#39;Validation loss&#39;) plt.title(&#39;Training and Validation Loss&#39;) plt.xlabel(&#39;Epoch&#39;) plt.ylabel(&#39;Loss Value&#39;) plt.ylim([0, 1]) plt.legend() plt.show() . Make predictions . Let&#39;s make some predictions. In the interest of saving time, the number of epochs was kept small, but you may set this higher to achieve more accurate results. . show_predictions(test_dataset, 3) .",
            "url": "https://rafaelsf80.github.io/blog/computer%20vision/2020/09/10/segmentation-mixedprecission.html",
            "relUrl": "/computer%20vision/2020/09/10/segmentation-mixedprecission.html",
            "date": " • Sep 10, 2020"
        }
        
    
  
    
        ,"post7": {
            "title": "AutoML NLP Classifier with a large confussion matrix",
            "content": "1. Introducci&#243;n . This notebook shows how to predict an existing trained model using AutoML NLP, in order to manually get bigger than 10x10 confussion matrix, which is the maximum supported by the AutoML service . We will use a public dataset about Stack Overflow questions available in Google Cloud marketplace, that has been trained using AutoML NLP. You can explore the dataset in BigQuery just by following the instructions of the former link. In this notebook,the model is already built and deployed in AutoML NLP service. To keep things simple our pre-processed table includes questions containing 4 possible programming-related tags: Java, Javascript, Python or C#. Confussion matrix bigger than 10x10 will be implied. . BigQuery has a public dataset that includes more than 17 million Stack Overflow questions. We are going to download some posts labeled as one of the four most used languages today: java, javascript, python and C#, but to make this a harder problem to our model, we have replaced every instance of that word with another less used language today (but well-known some decades ago) called blank. Otherwise, it will be very easy for the model to detect that a post is a java-related post just by finding the word java on it. . You can access the pre-processed fortran-filled dataset as a tar file here. Each of the four labels has approximate 10k samples for training/eval and 10k samples for test. . 2. Instalaci&#243;n . Authenticate in Google Cloud from Colab . from google.colab import auth auth.authenticate_user() print(&#39;Authenticated&#39;) . 3. Llamada a AutoML NLP (batch predict) . We will make a batch predict on an already deployed AutoML NLP model . # Batch predict for an already trained AutoML NLP model from google.cloud import automl project_id = &quot;windy-site-254307&quot; model_id = &quot;TCN627409922111307776&quot; input_uri = &quot;gs://stackoverflow-automl-nlp/dataset_batchpredict.csv&quot; output_uri = &quot;gs://stackoverflow-automl-nlp&quot; prediction_client = automl.PredictionServiceClient() # Get the full path of the model. model_full_id = prediction_client.model_path( project_id, &quot;us-central1&quot;, model_id ) gcs_source = automl.types.GcsSource(input_uris=[input_uri]) input_config = automl.types.BatchPredictInputConfig(gcs_source=gcs_source) gcs_destination = automl.types.GcsDestination(output_uri_prefix=output_uri) output_config = automl.types.BatchPredictOutputConfig( gcs_destination=gcs_destination ) response = prediction_client.batch_predict( model_full_id, input_config, output_config ) print(&quot;Waiting for operation to complete...&quot;) print( &quot;Batch Prediction results saved to Cloud Storage bucket. {}&quot;.format( response.result() ) ) . # Download results from GCS. See first line for reference and modify URI accordingly result = !gsutil ls gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z file_list = [] for i in range(len(result)): file = result[i] !gsutil cp $file . file_list.append( result[i].split(&#39;/&#39;)[4].strip() ) . Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_1.jsonl... Operation completed over 1 objects/120.0 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_10.jsonl... Operation completed over 1 objects/221.5 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_11.jsonl... Operation completed over 1 objects/96.5 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_12.jsonl... Operation completed over 1 objects/24.6 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_13.jsonl... Operation completed over 1 objects/26.7 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_14.jsonl... Operation completed over 1 objects/10.7 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_15.jsonl... Operation completed over 1 objects/37.2 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_16.jsonl... Operation completed over 1 objects/60.5 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_17.jsonl... Operation completed over 1 objects/21.3 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_18.jsonl... Operation completed over 1 objects/14.8 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_19.jsonl... Operation completed over 1 objects/47.1 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_2.jsonl... Operation completed over 1 objects/87.8 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_20.jsonl... Operation completed over 1 objects/27.4 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_21.jsonl... Operation completed over 1 objects/8.2 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_22.jsonl... Operation completed over 1 objects/6.6 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_23.jsonl... Operation completed over 1 objects/206.2 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_24.jsonl... Operation completed over 1 objects/199.6 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_25.jsonl... Operation completed over 1 objects/60.5 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_26.jsonl... Operation completed over 1 objects/46.7 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_27.jsonl... Operation completed over 1 objects/59.4 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_28.jsonl... Operation completed over 1 objects/31.6 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_29.jsonl... Operation completed over 1 objects/9.2 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_3.jsonl... Operation completed over 1 objects/107.3 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_30.jsonl... Operation completed over 1 objects/4.1 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_31.jsonl... Operation completed over 1 objects/103.1 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_32.jsonl... Operation completed over 1 objects/94.4 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_4.jsonl... Operation completed over 1 objects/18.5 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_5.jsonl... Operation completed over 1 objects/45.5 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_6.jsonl... Operation completed over 1 objects/35.1 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_7.jsonl... Operation completed over 1 objects/64.5 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_8.jsonl... Operation completed over 1 objects/42.6 KiB. Copying gs://stackoverflow-automl-nlp/prediction-stackoverflow_4labels_20200602-2020-06-29T08:49:31.326Z/text_classification_9.jsonl... / [0 files][ 0.0 B/ 98.1 KiB]/ [1 files][ 98.1 KiB/ 98.1 KiB] Operation completed over 1 objects/98.1 KiB. . 4. Procesar resultados . # Example of annotations # [{&#39;annotationSpecId&#39;: &#39;1249570775711612928&#39;, &#39;classification&#39;: {&#39;score&#39;: 0.020207971}, &#39;displayName&#39;: &#39;java&#39;}, {&#39;annotationSpecId&#39;: &#39;2402492280318459904&#39;, &#39;classification&#39;: {&#39;score&#39;: 0.96145684}, &#39;displayName&#39;: &#39;csharp&#39;}, {&#39;annotationSpecId&#39;: &#39;5861256794139000832&#39;, &#39;classification&#39;: {&#39;score&#39;: 0.0013875663000000001}, &#39;displayName&#39;: &#39;javascript&#39;}, {&#39;annotationSpecId&#39;: &#39;7014178298745847808&#39;, &#39;classification&#39;: {&#39;score&#39;: 0.017511099999999998}, &#39;displayName&#39;: &#39;python&#39;}] # Example of textSnippet # {&#39;contentUri&#39;: &#39;gs://stackoverflow-automl-nlp/test/csharp/1003.txt&#39;} import pandas as pd # Init enum from enum import Enum class Language(Enum): java = 0 csharp = 1 javascript = 2 python = 3 # Init vectors for the confussion matrix y_true = [] y_pred = [] # Read downloaded files one by one and generate y_true and y_pred vectos for the confussion matrix for file in file_list: #file=&quot;text_classification_1.jsonl&quot; # Read file df = pd.read_json(file, lines=True) print(&quot;Reading {0} annotations and {1} text snippets of {2}&quot;.format(len(df[&#39;annotations&#39;].to_list()), len(df[&#39;textSnippet&#39;].to_list()), file)) import json for i in range(len(df[&#39;annotations&#39;].to_list())): # Decode textSnippet and get true_label textsnippet_str = str(df[&#39;textSnippet&#39;].to_list()[i]).replace(&quot;&#39;&quot;, &#39;&quot;&#39;) textsnippet_decoded = json.loads(textsnippet_str) true_label = textsnippet_decoded[&#39;contentUri&#39;].split(&#39;/&#39;)[4].strip() y_true.append(true_label) # Decode annotations annotation_str = str(df[&#39;annotations&#39;].to_list()[i]).replace(&quot;&#39;&quot;, &#39;&quot;&#39;) annotation_decoded = json.loads(annotation_str) # Decode scores and add them to the corresponding line in the confussion matrix scores = [annotation_decoded[Language[&#39;java&#39;].value][&#39;classification&#39;][&#39;score&#39;], annotation_decoded[Language[&#39;csharp&#39;].value][&#39;classification&#39;][&#39;score&#39;], annotation_decoded[Language[&#39;javascript&#39;].value][&#39;classification&#39;][&#39;score&#39;], annotation_decoded[Language[&#39;python&#39;].value][&#39;classification&#39;][&#39;score&#39;]] max_value = max(scores) max_index = scores.index(max_value) y_pred.append(Language(max_index).name) . Reading 236 annotations and 236 text snippets of text_classification_1.jsonl Reading 435 annotations and 435 text snippets of text_classification_10.jsonl Reading 190 annotations and 190 text snippets of text_classification_11.jsonl Reading 48 annotations and 48 text snippets of text_classification_12.jsonl Reading 52 annotations and 52 text snippets of text_classification_13.jsonl Reading 21 annotations and 21 text snippets of text_classification_14.jsonl Reading 73 annotations and 73 text snippets of text_classification_15.jsonl Reading 119 annotations and 119 text snippets of text_classification_16.jsonl Reading 42 annotations and 42 text snippets of text_classification_17.jsonl Reading 29 annotations and 29 text snippets of text_classification_18.jsonl Reading 92 annotations and 92 text snippets of text_classification_19.jsonl Reading 172 annotations and 172 text snippets of text_classification_2.jsonl Reading 54 annotations and 54 text snippets of text_classification_20.jsonl Reading 16 annotations and 16 text snippets of text_classification_21.jsonl Reading 13 annotations and 13 text snippets of text_classification_22.jsonl Reading 405 annotations and 405 text snippets of text_classification_23.jsonl Reading 392 annotations and 392 text snippets of text_classification_24.jsonl Reading 119 annotations and 119 text snippets of text_classification_25.jsonl Reading 92 annotations and 92 text snippets of text_classification_26.jsonl Reading 116 annotations and 116 text snippets of text_classification_27.jsonl Reading 62 annotations and 62 text snippets of text_classification_28.jsonl Reading 18 annotations and 18 text snippets of text_classification_29.jsonl Reading 211 annotations and 211 text snippets of text_classification_3.jsonl Reading 8 annotations and 8 text snippets of text_classification_30.jsonl Reading 203 annotations and 203 text snippets of text_classification_31.jsonl Reading 185 annotations and 185 text snippets of text_classification_32.jsonl Reading 36 annotations and 36 text snippets of text_classification_4.jsonl Reading 89 annotations and 89 text snippets of text_classification_5.jsonl Reading 69 annotations and 69 text snippets of text_classification_6.jsonl Reading 127 annotations and 127 text snippets of text_classification_7.jsonl Reading 84 annotations and 84 text snippets of text_classification_8.jsonl Reading 192 annotations and 192 text snippets of text_classification_9.jsonl . Get confusion matrix . from sklearn.metrics import confusion_matrix matriz_de_confusion = confusion_matrix(y_true, y_pred, labels=[&quot;java&quot;, &quot;javascript&quot;, &quot;csharp&quot;, &quot;python&quot;]) #DO NOT USE THIS MATRIX #conf_max_12x12 = confusion_matrix(y_train, y_train_pred) #conf_max_12x12=([[1000, 3, 24, 9, 10, 49, 49, 50, 26, 23, 12, 98 ], # [ 23, 2000, 24, 9, 10, 49, 49, 50, 26, 23, 12, 98 ], # [ 56, 3, 1300, 9, 10, 49, 49, 50, 26, 23, 12, 98 ], # [ 23, 3, 24, 1400, 10, 49, 49, 50, 26, 23, 12, 98 ], # [ 35, 3, 24, 9, 1500, 49, 49, 50, 26, 23, 12, 98 ], # [ 35, 3, 24, 9, 10, 1400, 49, 50, 26, 23, 12, 98 ], # [ 35, 3, 24, 9, 10, 49, 1300, 50, 26, 23, 12, 98 ], # [ 35, 3, 24, 9, 10, 49, 49, 1200, 26, 23, 12, 98 ], # [ 35, 3, 24, 9, 10, 49, 49, 50, 1100, 23, 12, 98 ], # [ 35, 3, 24, 9, 10, 49, 49, 50, 26, 1000, 12, 98 ], # [ 35, 3, 24, 9, 10, 49, 49, 50, 26, 23, 1100, 98 ], # [ 35, 3, 24, 9, 10, 49, 49, 50, 26, 23, 12, 1200 ]]) . #!pip3 install seaborn import matplotlib.pyplot as plt import numpy as np import seaborn as sns # Normalise and Plot target_names = [&#39;java&#39;, &#39;csharp&#39;, &#39;javascript&#39;, &#39;python&#39;] cmn = matriz_de_confusion.astype(&#39;float&#39;) / matriz_de_confusion.sum(axis=1)[:, np.newaxis] fig, ax = plt.subplots(figsize=(10,10)) sns.heatmap(cmn, annot=True, fmt=&#39;.2f&#39;, xticklabels=target_names, yticklabels=target_names) plt.ylabel(&#39;Actual&#39;) plt.xlabel(&#39;Predicted&#39;) plt.show(block=False) . &lt;!DOCTYPE svg PUBLIC &quot;-//W3C//DTD SVG 1.1//EN&quot; &quot;http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd&quot;&gt;",
            "url": "https://rafaelsf80.github.io/blog/natural%20language%20processing/vertex%20ai/2020/06/26/automl-nlp-classifier-with-confussion-matrix.html",
            "relUrl": "/natural%20language%20processing/vertex%20ai/2020/06/26/automl-nlp-classifier-with-confussion-matrix.html",
            "date": " • Jun 26, 2020"
        }
        
    
  
    
        ,"post8": {
            "title": "Explainable AI in Spanish",
            "content": "Introducci&#243;n . Aviso: la versión original en inglés de este notebook está en este Codelab . Instalaci&#243;n . import itertools import numpy as np import pandas as pd import tensorflow as tf import json import matplotlib.pyplot as plt from sklearn.utils import shuffle from sklearn.metrics import confusion_matrix . Carga de datos . Es un dataset sintético de Kaggle, con trasacciones fraudulentas. Son 6.3 millones de registros, y 8000 son fraudulentas (sólo el 0.1!) . !gsutil cp gs://financial_fraud_detection/fraud_data_kaggle.csv . . Copying gs://financial_fraud_detection/fraud_data_kaggle.csv... | [1 files][470.7 MiB/470.7 MiB] Operation completed over 1 objects/470.7 MiB. . data = pd.read_csv(&#39;fraud_data_kaggle.csv&#39;) data.head() data.size . 69988820 . data[&#39;isFraud&#39;].value_counts() . 0 6354407 1 8213 Name: isFraud, dtype: int64 . Corregir datos desbalanceados . Usamos DOWNSAMPLING: consiste en usar todos los fraudulentos (8000) y solo 0.005 (31000) de los no-fraudulentos (clase minoritaria) . fraud = data[data[&#39;isFraud&#39;] == 1] not_fraud = data[data[&#39;isFraud&#39;] == 0] . # Take a random sample of non fraud rows not_fraud_sample = not_fraud.sample(random_state=2, frac=.005) # Put it back together and shuffle df = pd.concat([not_fraud_sample,fraud]) df = shuffle(df, random_state=2) # Remove a few columns (isFraud is the label column we&#39;ll use, not isFlaggedFraud) df = df.drop(columns=[&#39;nameOrig&#39;, &#39;nameDest&#39;, &#39;isFlaggedFraud&#39;]) # Preview the updated dataset df.head() . step type amount oldbalanceOrg newbalanceOrig oldbalanceDest newbalanceDest isFraud . 5777870 400 | PAYMENT | 65839.41 | 0.00 | 0.00 | 0.0 | 0.0 | 0 | . 6362412 726 | TRANSFER | 561446.32 | 561446.32 | 0.00 | 0.0 | 0.0 | 1 | . 5927827 404 | PAYMENT | 3828.08 | 10455.17 | 6627.09 | 0.0 | 0.0 | 0 | . 5987904 410 | TRANSFER | 557950.06 | 557950.06 | 0.00 | 0.0 | 0.0 | 1 | . 5706694 398 | PAYMENT | 1376.57 | 368349.14 | 366972.57 | 0.0 | 0.0 | 0 | . df[&#39;isFraud&#39;].value_counts() . 0 31772 1 8213 Name: isFraud, dtype: int64 . Dividir entre set de entrenamiento y prueba (test) . train_test_split = int(len(df) * .8) train_set = df[:train_test_split] test_set = df[train_test_split:] train_labels = train_set.pop(&#39;isFraud&#39;) test_labels = test_set.pop(&#39;isFraud&#39;) . Definir features . fc = tf.feature_column CATEGORICAL_COLUMNS = [&#39;type&#39;] NUMERIC_COLUMNS = [&#39;step&#39;, &#39;amount&#39;, &#39;oldbalanceOrg&#39;, &#39;newbalanceOrig&#39;, &#39;oldbalanceDest&#39;, &#39;newbalanceDest&#39;] . def one_hot_cat_column(feature_name, vocab): return tf.feature_column.indicator_column(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocab)) feature_columns = [] for feature_name in CATEGORICAL_COLUMNS: vocabulary = train_set[feature_name].unique() feature_columns.append(one_hot_cat_column(feature_name, vocabulary)) for feature_name in NUMERIC_COLUMNS: feature_columns.append(tf.feature_column.numeric_column(feature_name, dtype=tf.float32)) . Funciones . NUM_EXAMPLES = len(train_labels) def make_input_fn(X, y, n_epochs=None, shuffle=True): def input_fn(): dataset = tf.data.Dataset.from_tensor_slices((dict(X), y)) if shuffle: dataset = dataset.shuffle(NUM_EXAMPLES) dataset = dataset.repeat(n_epochs) dataset = dataset.batch(NUM_EXAMPLES) return dataset return input_fn # Define training and evaluation input functions train_input_fn = make_input_fn(train_set, train_labels) eval_input_fn = make_input_fn(test_set, test_labels, shuffle=False, n_epochs=1) . Entrenar modelo Boosted Tree . n_batches = 1 model = tf.estimator.BoostedTreesClassifier(feature_columns, n_batches_per_layer=n_batches) . INFO:tensorflow:Using default config. WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8ko2kwtc INFO:tensorflow:Using config: {&#39;_model_dir&#39;: &#39;/tmp/tmp8ko2kwtc&#39;, &#39;_tf_random_seed&#39;: None, &#39;_save_summary_steps&#39;: 100, &#39;_save_checkpoints_steps&#39;: None, &#39;_save_checkpoints_secs&#39;: 600, &#39;_session_config&#39;: allow_soft_placement: true graph_options { rewrite_options { meta_optimizer_iterations: ONE } } , &#39;_keep_checkpoint_max&#39;: 5, &#39;_keep_checkpoint_every_n_hours&#39;: 10000, &#39;_log_step_count_steps&#39;: 100, &#39;_train_distribute&#39;: None, &#39;_device_fn&#39;: None, &#39;_protocol&#39;: None, &#39;_eval_distribute&#39;: None, &#39;_experimental_distribute&#39;: None, &#39;_experimental_max_worker_delay_secs&#39;: None, &#39;_session_creation_timeout_secs&#39;: 7200, &#39;_service&#39;: None, &#39;_cluster_spec&#39;: &lt;tensorflow.python.training.server_lib.ClusterSpec object at 0x7fcb4fb77810&gt;, &#39;_task_type&#39;: &#39;worker&#39;, &#39;_task_id&#39;: 0, &#39;_global_id_in_cluster&#39;: 0, &#39;_master&#39;: &#39;&#39;, &#39;_evaluation_master&#39;: &#39;&#39;, &#39;_is_chief&#39;: True, &#39;_num_ps_replicas&#39;: 0, &#39;_num_worker_replicas&#39;: 1} WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py:369: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version. Instructions for updating: The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead. . model.train(train_input_fn, max_steps=100) . WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version. Instructions for updating: If using Keras pass *_constraint arguments to layers. WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version. Instructions for updating: Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts. INFO:tensorflow:Calling model_fn. WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4271: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version. Instructions for updating: The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead. WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/boosted_trees.py:214: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.cast` instead. WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/canned/head.py:437: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.cast` instead. WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version. Instructions for updating: Use tf.where in 2.0, which has the same broadcast rule as np.where INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Create CheckpointSaverHook. WARNING:tensorflow:Issue encountered when serializing resources. Type is unsupported, or the types of the items don&#39;t match field type in CollectionDef. Note this is a warning and probably safe to ignore. &#39;_Resource&#39; object has no attribute &#39;name&#39; INFO:tensorflow:Graph was finalized. INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. WARNING:tensorflow:Issue encountered when serializing resources. Type is unsupported, or the types of the items don&#39;t match field type in CollectionDef. Note this is a warning and probably safe to ignore. &#39;_Resource&#39; object has no attribute &#39;name&#39; INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp8ko2kwtc/model.ckpt. WARNING:tensorflow:Issue encountered when serializing resources. Type is unsupported, or the types of the items don&#39;t match field type in CollectionDef. Note this is a warning and probably safe to ignore. &#39;_Resource&#39; object has no attribute &#39;name&#39; INFO:tensorflow:loss = 0.6931538, step = 0 WARNING:tensorflow:It seems that global step (tf.train.get_global_step) has not been increased. Current value (could be stable): 0 vs previous value: 0. You could increase the global step by passing tf.train.get_global_step() to Optimizer.apply_gradients or Optimizer.minimize. INFO:tensorflow:global_step/sec: 1.56855 INFO:tensorflow:loss = 0.022666413, step = 99 (63.755 sec) INFO:tensorflow:Saving checkpoints for 100 into /tmp/tmp8ko2kwtc/model.ckpt. WARNING:tensorflow:Issue encountered when serializing resources. Type is unsupported, or the types of the items don&#39;t match field type in CollectionDef. Note this is a warning and probably safe to ignore. &#39;_Resource&#39; object has no attribute &#39;name&#39; INFO:tensorflow:Loss for final step: 0.022666413. . &lt;tensorflow_estimator.python.estimator.canned.boosted_trees.BoostedTreesClassifier at 0x7fcb4fb71dd0&gt; . result = model.evaluate(eval_input_fn) print(pd.Series(result)) . INFO:tensorflow:Calling model_fn. WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow_core/python/ops/metrics_impl.py:2026: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version. Instructions for updating: Deprecated in favor of operator or tf.math.divide. WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to &#34;careful_interpolation&#34; instead. WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to &#34;careful_interpolation&#34; instead. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Starting evaluation at 2020-06-22T08:11:13Z INFO:tensorflow:Graph was finalized. INFO:tensorflow:Restoring parameters from /tmp/tmp8ko2kwtc/model.ckpt-100 INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. INFO:tensorflow:Finished evaluation at 2020-06-22-08:11:15 INFO:tensorflow:Saving dict for global step 100: accuracy = 0.9949981, accuracy_baseline = 0.8006753, auc = 0.99874365, auc_precision_recall = 0.99814403, average_loss = 0.024392342, global_step = 100, label/mean = 0.19932474, loss = 0.024392342, precision = 0.97903824, prediction/mean = 0.2005636, recall = 0.9962359 WARNING:tensorflow:Issue encountered when serializing resources. Type is unsupported, or the types of the items don&#39;t match field type in CollectionDef. Note this is a warning and probably safe to ignore. &#39;_Resource&#39; object has no attribute &#39;name&#39; INFO:tensorflow:Saving &#39;checkpoint_path&#39; summary for global step 100: /tmp/tmp8ko2kwtc/model.ckpt-100 accuracy 0.994998 accuracy_baseline 0.800675 auc 0.998744 auc_precision_recall 0.998144 average_loss 0.024392 label/mean 0.199325 loss 0.024392 precision 0.979038 prediction/mean 0.200564 recall 0.996236 global_step 100.000000 dtype: float64 . pred_dicts = list(model.predict(eval_input_fn)) probabilities = pd.Series([pred[&#39;logistic&#39;][0] for pred in pred_dicts]) for i,val in enumerate(probabilities[:30]): print(&#39;Predicted: &#39;, round(val), &#39;Actual: &#39;, test_labels.iloc[i]) print() . INFO:tensorflow:Calling model_fn. INFO:tensorflow:Done calling model_fn. INFO:tensorflow:Graph was finalized. INFO:tensorflow:Restoring parameters from /tmp/tmp8ko2kwtc/model.ckpt-100 INFO:tensorflow:Running local_init_op. INFO:tensorflow:Done running local_init_op. Predicted: 0 Actual: 0 Predicted: 1 Actual: 1 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 1 Actual: 1 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 1 Actual: 1 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 Predicted: 0 Actual: 0 . Confusion matrix . y_pred = [] for i in probabilities.values: y_pred.append(int(round(i))) . cm = confusion_matrix(test_labels.values, y_pred) print(cm) . [[6369 34] [ 6 1588]] . def plot_confusion_matrix(cm, classes, normalize=False, title=&#39;Confusion matrix&#39;, cmap=plt.cm.Blues): &quot;&quot;&quot; This function prints and plots the confusion matrix. Normalization can be applied by setting `normalize=True`. &quot;&quot;&quot; plt.imshow(cm, interpolation=&#39;nearest&#39;, cmap=cmap) plt.title(title) plt.colorbar() tick_marks = np.arange(len(classes)) plt.xticks(tick_marks, classes, rotation=45) plt.yticks(tick_marks, classes) if normalize: cm = np.round(cm.astype(&#39;float&#39;) / cm.sum(axis=1)[:, np.newaxis], 3) thresh = cm.max() / 2. for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])): plt.text(j, i, cm[i, j], horizontalalignment=&quot;center&quot;, color=&quot;white&quot; if cm[i, j] &gt; thresh else &quot;black&quot;) plt.tight_layout() plt.ylabel(&#39;True label&#39;) plt.xlabel(&#39;Predicted label&#39;) . classes = [&#39;not fraud&#39;, &#39;fraud&#39;] plot_confusion_matrix(cm, classes, normalize=True) . Preparando el despliegue del modelo en AI Platform (con Explainability) . GCP_PROJECT = &#39;windy-site-254307&#39; MODEL_BUCKET = &#39;gs://fraud-detection-explainable-ai&#39; !gsutil mb $MODEL_BUCKET . Creating gs://fraud-detection-explainable-ai/... ServiceException: 409 Bucket fraud-detection-explainable-ai already exists. . Exportamos el modelo en TensorFlow 1.x . import tensorflow.compat.v1 as tf tf.disable_v2_behavior() def json_serving_input_fn(): inputs = {} for feat in feature_columns: if feat.name == &quot;type_indicator&quot;: inputs[&#39;type&#39;] = tf.placeholder(shape=[None], name=feat.name, dtype=tf.string) else: inputs[feat.name] = tf.placeholder(shape=[None], name=feat.name, dtype=feat.dtype) return tf.estimator.export.ServingInputReceiver(inputs, inputs) export_path = model.export_saved_model( MODEL_BUCKET + &#39;/explanations&#39;, serving_input_receiver_fn=json_serving_input_fn ).decode(&#39;utf-8&#39;) tf.enable_v2_behavior() . !saved_model_cli show --dir $export_path --all . MetaGraphDef with tag-set: &#39;serve&#39; contains the following SignatureDefs: signature_def[&#39;predict&#39;]: The given SavedModel SignatureDef contains the following input(s): inputs[&#39;amount&#39;] tensor_info: dtype: DT_FLOAT shape: (-1) name: amount:0 inputs[&#39;newbalanceDest&#39;] tensor_info: dtype: DT_FLOAT shape: (-1) name: newbalanceDest:0 inputs[&#39;newbalanceOrig&#39;] tensor_info: dtype: DT_FLOAT shape: (-1) name: newbalanceOrig:0 inputs[&#39;oldbalanceDest&#39;] tensor_info: dtype: DT_FLOAT shape: (-1) name: oldbalanceDest:0 inputs[&#39;oldbalanceOrg&#39;] tensor_info: dtype: DT_FLOAT shape: (-1) name: oldbalanceOrg:0 inputs[&#39;step&#39;] tensor_info: dtype: DT_FLOAT shape: (-1) name: step:0 inputs[&#39;type&#39;] tensor_info: dtype: DT_STRING shape: (-1) name: type_indicator:0 The given SavedModel SignatureDef contains the following output(s): outputs[&#39;all_class_ids&#39;] tensor_info: dtype: DT_INT32 shape: (-1, 2) name: boosted_trees/head/predictions/Tile:0 outputs[&#39;all_classes&#39;] tensor_info: dtype: DT_STRING shape: (-1, 2) name: boosted_trees/head/predictions/Tile_1:0 outputs[&#39;class_ids&#39;] tensor_info: dtype: DT_INT64 shape: (-1, 1) name: boosted_trees/head/predictions/ExpandDims:0 outputs[&#39;classes&#39;] tensor_info: dtype: DT_STRING shape: (-1, 1) name: boosted_trees/head/predictions/str_classes:0 outputs[&#39;logistic&#39;] tensor_info: dtype: DT_FLOAT shape: (-1, 1) name: boosted_trees/head/predictions/logistic:0 outputs[&#39;logits&#39;] tensor_info: dtype: DT_FLOAT shape: (-1, 1) name: boosted_trees/BoostedTreesPredict:0 outputs[&#39;probabilities&#39;] tensor_info: dtype: DT_FLOAT shape: (-1, 2) name: boosted_trees/head/predictions/probabilities:0 Method name is: tensorflow/serving/predict . not_fraud.median() . step 239.00 amount 74684.72 oldbalanceOrg 14069.00 newbalanceOrig 0.00 oldbalanceDest 133311.80 newbalanceDest 214881.70 isFraud 0.00 isFlaggedFraud 0.00 dtype: float64 . not_fraud[&#39;type&#39;].value_counts() . CASH_OUT 2233384 PAYMENT 2151495 CASH_IN 1399284 TRANSFER 528812 DEBIT 41432 Name: type, dtype: int64 . !gsutil cp explanation_metadata.json $export_path . Copying file://explanation_metadata.json [Content-Type=application/json]... / [1 files][ 718.0 B/ 718.0 B] Operation completed over 1 objects/718.0 B. . !gsutil cp gs://fraud-detection-explainable-ai/explanations/1592218671/explanation_metadata.json . !gsutil cp explanation_metadata.json $export_path . Despliegue e AI Platform explanations . MODEL = &#39;fraud_detection_4&#39; VERSION = &#39;v3&#39; . !gcloud ai-platform models create $MODEL . WARNING: Using endpoint [https://ml.googleapis.com/] WARNING: Please explicitly specify a region. Using [us-central1] by default on https://ml.googleapis.com. Please note that your model will be inaccessible from https://us-central1-ml.googelapis.com Learn more about regional endpoints and see a list of available regions: https://cloud.google.com/ai-platform/prediction/docs/regional-endpoints ERROR: (gcloud.ai-platform.models.create) Resource in project [windy-site-254307] is the subject of a conflict: Field: model.name Error: A model with the same name already exists. - &#39;@type&#39;: type.googleapis.com/google.rpc.BadRequest fieldViolations: - description: A model with the same name already exists. field: model.name . !gcloud beta ai-platform versions create v3 --model $MODEL --origin $export_path --runtime-version 1.15 --framework TENSORFLOW --python-version 3.7 --machine-type n1-standard-4 --explanation-method &#39;sampled-shapley&#39; --num-paths 10 . WARNING: Using endpoint [https://ml.googleapis.com/] Explanations reflect patterns in your model, but don&#39;t necessarily reveal fundamental relationships about your data population. See https://cloud.google.com/ml-engine/docs/ai-explanations/limitations for more information. ERROR: (gcloud.beta.ai-platform.versions.create) ALREADY_EXISTS: Field: version.name Error: A version with the same name already exists. - &#39;@type&#39;: type.googleapis.com/google.rpc.BadRequest fieldViolations: - description: A version with the same name already exists. field: version.name . !gcloud ai-platform versions describe $VERSION --model $MODEL . WARNING: Using endpoint [https://ml.googleapis.com/] createTime: &#39;2020-06-15T14:20:08Z&#39; deploymentUri: gs://fraud-detection-explainable-ai/explanations/1592230714 etag: yuDcVfyBSAQ= explanationConfig: sampledShapleyAttribution: numPaths: 10 framework: TENSORFLOW isDefault: true lastUseTime: &#39;2020-06-18T07:20:48Z&#39; machineType: n1-standard-4 name: projects/windy-site-254307/models/fraud_detection_4/versions/v3 pythonVersion: &#39;3.7&#39; runtimeVersion: &#39;1.15&#39; state: READY . Predicci&#243;n con explicabilidad . Paso 1: preparamos datos (data.txt) . fraud_indices = [] for i,val in enumerate(test_labels): if val == 1: fraud_indices.append(i) . num_test_examples = 5 import numpy as np def convert(o): if isinstance(o, np.generic): return o.item() raise TypeError for i in range(num_test_examples): test_json = {} ex = test_set.iloc[fraud_indices[i]] keys = ex.keys().tolist() vals = ex.values.tolist() for idx in range(len(keys)): test_json[keys[idx]] = vals[idx] print(test_json) with open(&#39;data.txt&#39;, &#39;a&#39;) as outfile: json.dump(test_json, outfile, default=convert) outfile.write(&#39; n&#39;) . {&#39;step&#39;: 476, &#39;type&#39;: &#39;TRANSFER&#39;, &#39;amount&#39;: 1048.63, &#39;oldbalanceOrg&#39;: 1048.63, &#39;newbalanceOrig&#39;: 0.0, &#39;oldbalanceDest&#39;: 0.0, &#39;newbalanceDest&#39;: 0.0} {&#39;step&#39;: 390, &#39;type&#39;: &#39;TRANSFER&#39;, &#39;amount&#39;: 638693.49, &#39;oldbalanceOrg&#39;: 638693.49, &#39;newbalanceOrig&#39;: 0.0, &#39;oldbalanceDest&#39;: 0.0, &#39;newbalanceDest&#39;: 0.0} {&#39;step&#39;: 355, &#39;type&#39;: &#39;CASH_OUT&#39;, &#39;amount&#39;: 5338162.8, &#39;oldbalanceOrg&#39;: 5338162.8, &#39;newbalanceOrig&#39;: 0.0, &#39;oldbalanceDest&#39;: 181895.58, &#39;newbalanceDest&#39;: 5520058.37} {&#39;step&#39;: 356, &#39;type&#39;: &#39;TRANSFER&#39;, &#39;amount&#39;: 357226.8, &#39;oldbalanceOrg&#39;: 357226.8, &#39;newbalanceOrig&#39;: 0.0, &#39;oldbalanceDest&#39;: 0.0, &#39;newbalanceDest&#39;: 0.0} {&#39;step&#39;: 345, &#39;type&#39;: &#39;TRANSFER&#39;, &#39;amount&#39;: 128936.95, &#39;oldbalanceOrg&#39;: 128936.95, &#39;newbalanceOrig&#39;: 0.0, &#39;oldbalanceDest&#39;: 0.0, &#39;newbalanceDest&#39;: 0.0} . !cat data.txt . {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 476, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 1048.63, &#34;oldbalanceOrg&#34;: 1048.63, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 390, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 638693.49, &#34;oldbalanceOrg&#34;: 638693.49, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 355, &#34;type&#34;: &#34;CASH_OUT&#34;, &#34;amount&#34;: 5338162.8, &#34;oldbalanceOrg&#34;: 5338162.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 181895.58, &#34;newbalanceDest&#34;: 5520058.37} {&#34;step&#34;: 356, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 357226.8, &#34;oldbalanceOrg&#34;: 357226.8, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} {&#34;step&#34;: 345, &#34;type&#34;: &#34;TRANSFER&#34;, &#34;amount&#34;: 128936.95, &#34;oldbalanceOrg&#34;: 128936.95, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;newbalanceDest&#34;: 0.0} . Step 2: enviamos data.txt al modelo con gcloud beta ai-platform explain . explanations = !gcloud beta ai-platform explain --model $MODEL --version $VERSION --json-instances=&#39;data.txt&#39; --verbosity error . &#39;{ &#34;explanations&#34;: [ { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.07222782395555333, &#34;attributions&#34;: { &#34;amount&#34;: 0.6966777056455612, &#34;newbalanceDest&#34;: 0.1639272928237915, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.16475289762020112, &#34;oldbalanceOrg&#34;: -0.15600235760211945, &#34;step&#34;: 0.1192602276802063, &#34;type&#34;: -0.027230754494667053 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9744548797607422, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.004716743469869621, &#34;attributions&#34;: { &#34;amount&#34;: -0.0019459187984466552, &#34;newbalanceDest&#34;: 0.007967007160186768, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.008247834444046021, &#34;oldbalanceOrg&#34;: 0.9784113168716431, &#34;step&#34;: 0.0, &#34;type&#34;: -0.007150697708129883 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9985994100570679, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.0024439054423102693, &#34;attributions&#34;: { &#34;amount&#34;: -0.002712637186050415, &#34;newbalanceDest&#34;: -0.0005802184343338013, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.0, &#34;oldbalanceOrg&#34;: 0.9835709899663925, &#34;step&#34;: 0.0, &#34;type&#34;: 0.0 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9933480024337769, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.014761328724187625, &#34;attributions&#34;: { &#34;amount&#34;: -0.02181842029094696, &#34;newbalanceDest&#34;: 0.029705092310905457, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.038540315628051755, &#34;oldbalanceOrg&#34;: 0.9493075281381607, &#34;step&#34;: 0.0, &#34;type&#34;: -0.011098328232765197 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9977060556411743, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] }, { &#34;attributions_by_label&#34;: [ { &#34;approx_error&#34;: 0.036956189992043476, &#34;attributions&#34;: { &#34;amount&#34;: -0.05543297529220581, &#34;newbalanceDest&#34;: 0.09204374849796296, &#34;newbalanceOrig&#34;: 0.0, &#34;oldbalanceDest&#34;: 0.09319761395454407, &#34;oldbalanceOrg&#34;: 0.8222974985837936, &#34;step&#34;: 0.0, &#34;type&#34;: 0.028654450178146364 }, &#34;baseline_score&#34;: 0.013069868087768555, &#34;example_score&#34;: 0.9938302040100098, &#34;label_index&#34;: 0, &#34;output_name&#34;: &#34;prob&#34; } ] } ] }&#39; . explain_dict = json.loads(explanations.s) . ### Step 3: análisis de datos (notad el baseline) . print(&#39;Model baseline for fraud cases: &#39;, explain_dict[&#39;explanations&#39;][0][&#39;attributions_by_label&#39;][0][&#39;baseline_score&#39;], &#39; n&#39;) . Model baseline for fraud cases: 0.013069868087768555 . for i in explain_dict[&#39;explanations&#39;]: prediction_score = i[&#39;attributions_by_label&#39;][0][&#39;example_score&#39;] attributions = i[&#39;attributions_by_label&#39;][0][&#39;attributions&#39;] print(&#39;Model prediction:&#39;, prediction_score) fig, ax = plt.subplots() ax.barh(list(attributions.keys()), list(attributions.values()), align=&#39;center&#39;) plt.show() . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 . Model prediction: 0.9744548797607422 . Model prediction: 0.9985994100570679 . Model prediction: 0.9933480024337769 . Model prediction: 0.9977060556411743 . Model prediction: 0.9938302040100098 .",
            "url": "https://rafaelsf80.github.io/blog/structured%20data/2020/06/20/xai-fraud-detection.html",
            "relUrl": "/structured%20data/2020/06/20/xai-fraud-detection.html",
            "date": " • Jun 20, 2020"
        }
        
    
  
    
        ,"post9": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . #collapse-hide import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . #collapse-show cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . #collapse-output print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # single-value selection over [Major_Genre, MPAA_Rating] pairs # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . # select a point for which to provide details-on-demand label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . # display table with pandas df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://rafaelsf80.github.io/blog/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post10": {
            "title": "Transfer Google Drive to GCS in Colab",
            "content": "from google.colab import drive . drive.mount(&#39;/content/drive&#39;) . project_id = &lt;YOUR_PROJECT_ID&gt; . !gcloud config set project $project_id . !gsutil ls . !gcloud auth login . !gsutil ls . !gsutil -m cp -r /content/drive/My Drive/a/06/* gs://BUCKET_NAME/06/ .",
            "url": "https://rafaelsf80.github.io/blog/quickrecipes/2020/02/01/transfer-Drive2GCS.html",
            "relUrl": "/quickrecipes/2020/02/01/transfer-Drive2GCS.html",
            "date": " • Feb 1, 2020"
        }
        
    
  
    
        ,"post11": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://rafaelsf80.github.io/blog/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "Site under construction . This is my Github page . This is my LinkedIn page .",
          "url": "https://rafaelsf80.github.io/blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://rafaelsf80.github.io/blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}